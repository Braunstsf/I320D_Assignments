{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17d2e265",
   "metadata": {},
   "source": [
    "# Assignment 4: Decision Trees and Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25fb768",
   "metadata": {},
   "source": [
    "<mark> Ethan Wen - Professor Mishra - 02/27/2022 </mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e6085d",
   "metadata": {},
   "source": [
    "This assignment is updated with an Ablation Test from the past assignment, Assignment 3: Logisitic Regression and SVMs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e680a",
   "metadata": {},
   "source": [
    "From Kaggle, we will be using data about Mount Rainier Weather and Climbing. The assingment asks us to develop a mobile application to determine whether one should climb Mount Rainier based on a set of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b70227",
   "metadata": {},
   "source": [
    "The features are: Battery Voltage AVG, Temperature AVG, Relative Humidity AVG, Wind Speed Daily AVG, Wind Direction AVG, Solar Radiation AVG, and Route. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fc17be",
   "metadata": {},
   "source": [
    "The outputs that we are trying to predict would be the column called **'Succeeded'**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e514186",
   "metadata": {},
   "source": [
    "Our output would be determined as either **0 or 1** which would stand for **don't hike and hike** Mt. Rainer respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c0a6b4",
   "metadata": {},
   "source": [
    "## 1. Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15d8f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a15d6dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data (1895, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "mtrainier_df = pd.read_csv(\"MtRainier_data.csv\")\n",
    "print (f\"Shape of data {mtrainier_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421796e7",
   "metadata": {},
   "source": [
    "As we can see here, the original dataset holds **10** columns and contains **1895** rows. The following code will try to find duplicates and drop columns that have missing data in one of their columns to make a better model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7b74d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data (1895, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Route</th>\n",
       "      <th>Succeeded</th>\n",
       "      <th>Battery Voltage AVG</th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11/27/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>0</td>\n",
       "      <td>13.643750</td>\n",
       "      <td>26.321667</td>\n",
       "      <td>19.715000</td>\n",
       "      <td>27.839583</td>\n",
       "      <td>68.004167</td>\n",
       "      <td>88.496250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11/21/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>0</td>\n",
       "      <td>13.749583</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>21.690708</td>\n",
       "      <td>2.245833</td>\n",
       "      <td>117.549667</td>\n",
       "      <td>93.660417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10/15/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>0</td>\n",
       "      <td>13.461250</td>\n",
       "      <td>46.447917</td>\n",
       "      <td>27.211250</td>\n",
       "      <td>17.163625</td>\n",
       "      <td>259.121375</td>\n",
       "      <td>138.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10/13/2015</td>\n",
       "      <td>Little Tahoma</td>\n",
       "      <td>0</td>\n",
       "      <td>13.532083</td>\n",
       "      <td>40.979583</td>\n",
       "      <td>28.335708</td>\n",
       "      <td>19.591167</td>\n",
       "      <td>279.779167</td>\n",
       "      <td>176.382667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10/9/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>0</td>\n",
       "      <td>13.216250</td>\n",
       "      <td>38.260417</td>\n",
       "      <td>74.329167</td>\n",
       "      <td>65.138333</td>\n",
       "      <td>264.687500</td>\n",
       "      <td>27.791292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date                   Route  Succeeded  \\\n",
       "0           0  11/27/2015  Disappointment Cleaver          0   \n",
       "1           1  11/21/2015  Disappointment Cleaver          0   \n",
       "2           2  10/15/2015  Disappointment Cleaver          0   \n",
       "3           3  10/13/2015           Little Tahoma          0   \n",
       "4           4   10/9/2015  Disappointment Cleaver          0   \n",
       "\n",
       "   Battery Voltage AVG  Temperature AVG  Relative Humidity AVG  \\\n",
       "0            13.643750        26.321667              19.715000   \n",
       "1            13.749583        31.300000              21.690708   \n",
       "2            13.461250        46.447917              27.211250   \n",
       "3            13.532083        40.979583              28.335708   \n",
       "4            13.216250        38.260417              74.329167   \n",
       "\n",
       "   Wind Speed Daily AVG  Wind Direction AVG  Solare Radiation AVG  \n",
       "0             27.839583           68.004167             88.496250  \n",
       "1              2.245833          117.549667             93.660417  \n",
       "2             17.163625          259.121375            138.387000  \n",
       "3             19.591167          279.779167            176.382667  \n",
       "4             65.138333          264.687500             27.791292  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainier_df = mtrainier_df.drop_duplicates()\n",
    "\n",
    "mtrainier_df = mtrainier_df.dropna()\n",
    "print (f\"Shape of data {mtrainier_df.shape}\")\n",
    "mtrainier_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba19de4",
   "metadata": {},
   "source": [
    "It seems like we have the same amount of rows so all of these data entries seem to be non-duplicates and aren't missing any data. However, there is an 'Unnamed' Section that replicates our index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc9c9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Date', 'Route', 'Succeeded', 'Battery Voltage AVG',\n",
       "       'Temperature AVG', 'Relative Humidity AVG', 'Wind Speed Daily AVG',\n",
       "       'Wind Direction AVG', 'Solare Radiation AVG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainier_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c784c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          1\n",
       "2          2\n",
       "3          3\n",
       "4          4\n",
       "        ... \n",
       "1890    1890\n",
       "1891    1891\n",
       "1892    1892\n",
       "1893    1893\n",
       "1894    1894\n",
       "Name: Unnamed: 0, Length: 1895, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Route</th>\n",
       "      <th>Succeeded</th>\n",
       "      <th>Battery Voltage AVG</th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/27/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>0</td>\n",
       "      <td>13.643750</td>\n",
       "      <td>26.321667</td>\n",
       "      <td>19.715000</td>\n",
       "      <td>27.839583</td>\n",
       "      <td>68.004167</td>\n",
       "      <td>88.496250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/21/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>0</td>\n",
       "      <td>13.749583</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>21.690708</td>\n",
       "      <td>2.245833</td>\n",
       "      <td>117.549667</td>\n",
       "      <td>93.660417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/15/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>0</td>\n",
       "      <td>13.461250</td>\n",
       "      <td>46.447917</td>\n",
       "      <td>27.211250</td>\n",
       "      <td>17.163625</td>\n",
       "      <td>259.121375</td>\n",
       "      <td>138.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/13/2015</td>\n",
       "      <td>Little Tahoma</td>\n",
       "      <td>0</td>\n",
       "      <td>13.532083</td>\n",
       "      <td>40.979583</td>\n",
       "      <td>28.335708</td>\n",
       "      <td>19.591167</td>\n",
       "      <td>279.779167</td>\n",
       "      <td>176.382667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/9/2015</td>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>0</td>\n",
       "      <td>13.216250</td>\n",
       "      <td>38.260417</td>\n",
       "      <td>74.329167</td>\n",
       "      <td>65.138333</td>\n",
       "      <td>264.687500</td>\n",
       "      <td>27.791292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                   Route  Succeeded  Battery Voltage AVG  \\\n",
       "0  11/27/2015  Disappointment Cleaver          0            13.643750   \n",
       "1  11/21/2015  Disappointment Cleaver          0            13.749583   \n",
       "2  10/15/2015  Disappointment Cleaver          0            13.461250   \n",
       "3  10/13/2015           Little Tahoma          0            13.532083   \n",
       "4   10/9/2015  Disappointment Cleaver          0            13.216250   \n",
       "\n",
       "   Temperature AVG  Relative Humidity AVG  Wind Speed Daily AVG  \\\n",
       "0        26.321667              19.715000             27.839583   \n",
       "1        31.300000              21.690708              2.245833   \n",
       "2        46.447917              27.211250             17.163625   \n",
       "3        40.979583              28.335708             19.591167   \n",
       "4        38.260417              74.329167             65.138333   \n",
       "\n",
       "   Wind Direction AVG  Solare Radiation AVG  \n",
       "0           68.004167             88.496250  \n",
       "1          117.549667             93.660417  \n",
       "2          259.121375            138.387000  \n",
       "3          279.779167            176.382667  \n",
       "4          264.687500             27.791292  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainier_df.pop(\"Unnamed: 0\")\n",
    "mtrainier_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce78498",
   "metadata": {},
   "source": [
    "One thing that I am confused about is the use of date as a feature or if its just useless. The other features seem to be more related to the prediction of a trip to Mt. Rainier being successful. For now, I will probably just use date as an index instead since we don't need it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328c3acb",
   "metadata": {},
   "source": [
    "Most of our features seem to be numerical: Battery Voltage AVG, Temperature AVG, Relative Humidity AVG, Wind Speed Daily AVG, Wind Direction AVG,and Solare Radiation AVG. However, Route and Succeeded are both categorical data. 'Route' is a **categorical nominal variable** since its talking about different summit routes while 'Succeeded' could be a **categorical nominal binary variable** since its talking about two different outcomes - not hiking and hiking - which are related to each other in order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc2d957c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1890    0\n",
       "1891    1\n",
       "1892    1\n",
       "1893    0\n",
       "1894    0\n",
       "Name: Succeeded, Length: 1895, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Route</th>\n",
       "      <th>Battery Voltage AVG</th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>13.643750</td>\n",
       "      <td>26.321667</td>\n",
       "      <td>19.715000</td>\n",
       "      <td>27.839583</td>\n",
       "      <td>68.004167</td>\n",
       "      <td>88.496250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>13.749583</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>21.690708</td>\n",
       "      <td>2.245833</td>\n",
       "      <td>117.549667</td>\n",
       "      <td>93.660417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>13.461250</td>\n",
       "      <td>46.447917</td>\n",
       "      <td>27.211250</td>\n",
       "      <td>17.163625</td>\n",
       "      <td>259.121375</td>\n",
       "      <td>138.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Little Tahoma</td>\n",
       "      <td>13.532083</td>\n",
       "      <td>40.979583</td>\n",
       "      <td>28.335708</td>\n",
       "      <td>19.591167</td>\n",
       "      <td>279.779167</td>\n",
       "      <td>176.382667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disappointment Cleaver</td>\n",
       "      <td>13.216250</td>\n",
       "      <td>38.260417</td>\n",
       "      <td>74.329167</td>\n",
       "      <td>65.138333</td>\n",
       "      <td>264.687500</td>\n",
       "      <td>27.791292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Route  Battery Voltage AVG  Temperature AVG  \\\n",
       "0  Disappointment Cleaver            13.643750        26.321667   \n",
       "1  Disappointment Cleaver            13.749583        31.300000   \n",
       "2  Disappointment Cleaver            13.461250        46.447917   \n",
       "3           Little Tahoma            13.532083        40.979583   \n",
       "4  Disappointment Cleaver            13.216250        38.260417   \n",
       "\n",
       "   Relative Humidity AVG  Wind Speed Daily AVG  Wind Direction AVG  \\\n",
       "0              19.715000             27.839583           68.004167   \n",
       "1              21.690708              2.245833          117.549667   \n",
       "2              27.211250             17.163625          259.121375   \n",
       "3              28.335708             19.591167          279.779167   \n",
       "4              74.329167             65.138333          264.687500   \n",
       "\n",
       "   Solare Radiation AVG  \n",
       "0             88.496250  \n",
       "1             93.660417  \n",
       "2            138.387000  \n",
       "3            176.382667  \n",
       "4             27.791292  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainier_labels_df = pd.DataFrame(mtrainier_df[[\"Succeeded\"]])\n",
    "mtrainier_df.pop(\"Succeeded\")\n",
    "mtrainier_dates_df = pd.DataFrame(mtrainier_df.pop(\"Date\")) #I don't think we need it but I'll save it. \n",
    "mtrainier_features_df = mtrainier_df\n",
    "mtrainier_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48533eb3",
   "metadata": {},
   "source": [
    "Before scaling, we need to deal with the **categorical nominal variable - Route**. Since its a categorical nominal variable, I will use one-hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91ba0e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Disappointment Cleaver', 'Disappointment Cleaver', 'Disappointment Cleaver', 'Little Tahoma', 'Disappointment Cleaver']\n"
     ]
    }
   ],
   "source": [
    "route_list = mtrainier_features_df[\"Route\"].to_list()\n",
    "print(route_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9685e9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Curtis RIngraham Directge',\n",
       " 'Disappointment Cleaver',\n",
       " 'Emmons-Winthrop',\n",
       " \"Fuhrer's Finger\",\n",
       " 'Fuhrers Finger',\n",
       " 'Gibralter Chute',\n",
       " 'Gibralter Ledges',\n",
       " 'Ingraham Direct',\n",
       " 'Kautz Cleaver',\n",
       " 'Kautz Glacier',\n",
       " 'Liberty RIngraham Directge',\n",
       " 'Little Tahoma',\n",
       " 'Mowich Face',\n",
       " 'Nisqually Glacier',\n",
       " 'Ptarmigan RIngraham Directge',\n",
       " 'Success Cleaver',\n",
       " 'Sunset RIngraham Directge',\n",
       " 'Tahoma Cleaver',\n",
       " 'Tahoma Glacier',\n",
       " 'Unknown',\n",
       " 'Wilson Headwall',\n",
       " 'glacier only - no summit attempt'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(route_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4b24020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Disappointment Cleaver'], ['Disappointment Cleaver'], ['Disappointment Cleaver'], ['Little Tahoma'], ['Disappointment Cleaver']]\n"
     ]
    }
   ],
   "source": [
    "route_list_of_lists = []\n",
    "\n",
    "for i in route_list: \n",
    "    route_list_of_lists.append([i])\n",
    "\n",
    "print(route_list_of_lists[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ab66ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique vocabulary items 22\n",
      "\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "route_encoder = OneHotEncoder()\n",
    "\n",
    "route_encoder.fit(route_list_of_lists)\n",
    "\n",
    "print(f\"Unique vocabulary items {len(route_encoder.categories_[0])}\\n\")\n",
    "\n",
    "route_transformed = route_encoder.transform(route_list_of_lists)\n",
    "\n",
    "route_transformed = route_transformed.toarray()\n",
    "\n",
    "print(route_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68d519d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(route_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78482a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_transformed_df = pd.DataFrame(route_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6f7496",
   "metadata": {},
   "source": [
    "Instead of replacing the labels one by one, I will use the method that I implemented in Assignment 2 to replace the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e218d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for i in range(len(route_transformed_df.columns)):\n",
    "    temp = list(route_transformed_df[i])\n",
    "    temp_list.append(temp.index(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f0404e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Curtis RIngraham Directge', 'Disappointment Cleaver', 'Emmons-Winthrop', \"Fuhrer's Finger\", 'Fuhrers Finger', 'Gibralter Chute', 'Gibralter Ledges', 'Ingraham Direct', 'Kautz Cleaver', 'Kautz Glacier', 'Liberty RIngraham Directge', 'Little Tahoma', 'Mowich Face', 'Nisqually Glacier', 'Ptarmigan RIngraham Directge', 'Success Cleaver', 'Sunset RIngraham Directge', 'Tahoma Cleaver', 'Tahoma Glacier', 'Unknown', 'Wilson Headwall', 'glacier only - no summit attempt']\n"
     ]
    }
   ],
   "source": [
    "route_name_list = []\n",
    "for i in temp_list:\n",
    "    route_name_list.append(mtrainier_features_df[\"Route\"][i])\n",
    "print(route_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cc3bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_transformed_df.columns = route_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f445fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Curtis RIngraham Directge</th>\n",
       "      <th>Disappointment Cleaver</th>\n",
       "      <th>Emmons-Winthrop</th>\n",
       "      <th>Fuhrer's Finger</th>\n",
       "      <th>Fuhrers Finger</th>\n",
       "      <th>Gibralter Chute</th>\n",
       "      <th>Gibralter Ledges</th>\n",
       "      <th>Ingraham Direct</th>\n",
       "      <th>Kautz Cleaver</th>\n",
       "      <th>Kautz Glacier</th>\n",
       "      <th>...</th>\n",
       "      <th>Mowich Face</th>\n",
       "      <th>Nisqually Glacier</th>\n",
       "      <th>Ptarmigan RIngraham Directge</th>\n",
       "      <th>Success Cleaver</th>\n",
       "      <th>Sunset RIngraham Directge</th>\n",
       "      <th>Tahoma Cleaver</th>\n",
       "      <th>Tahoma Glacier</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Wilson Headwall</th>\n",
       "      <th>glacier only - no summit attempt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Curtis RIngraham Directge  Disappointment Cleaver  Emmons-Winthrop  \\\n",
       "0                        0.0                     1.0              0.0   \n",
       "1                        0.0                     1.0              0.0   \n",
       "2                        0.0                     1.0              0.0   \n",
       "3                        0.0                     0.0              0.0   \n",
       "4                        0.0                     1.0              0.0   \n",
       "\n",
       "   Fuhrer's Finger  Fuhrers Finger  Gibralter Chute  Gibralter Ledges  \\\n",
       "0              0.0             0.0              0.0               0.0   \n",
       "1              0.0             0.0              0.0               0.0   \n",
       "2              0.0             0.0              0.0               0.0   \n",
       "3              0.0             0.0              0.0               0.0   \n",
       "4              0.0             0.0              0.0               0.0   \n",
       "\n",
       "   Ingraham Direct  Kautz Cleaver  Kautz Glacier  ...  Mowich Face  \\\n",
       "0              0.0            0.0            0.0  ...          0.0   \n",
       "1              0.0            0.0            0.0  ...          0.0   \n",
       "2              0.0            0.0            0.0  ...          0.0   \n",
       "3              0.0            0.0            0.0  ...          0.0   \n",
       "4              0.0            0.0            0.0  ...          0.0   \n",
       "\n",
       "   Nisqually Glacier  Ptarmigan RIngraham Directge  Success Cleaver  \\\n",
       "0                0.0                           0.0              0.0   \n",
       "1                0.0                           0.0              0.0   \n",
       "2                0.0                           0.0              0.0   \n",
       "3                0.0                           0.0              0.0   \n",
       "4                0.0                           0.0              0.0   \n",
       "\n",
       "   Sunset RIngraham Directge  Tahoma Cleaver  Tahoma Glacier  Unknown  \\\n",
       "0                        0.0             0.0             0.0      0.0   \n",
       "1                        0.0             0.0             0.0      0.0   \n",
       "2                        0.0             0.0             0.0      0.0   \n",
       "3                        0.0             0.0             0.0      0.0   \n",
       "4                        0.0             0.0             0.0      0.0   \n",
       "\n",
       "   Wilson Headwall  glacier only - no summit attempt  \n",
       "0              0.0                               0.0  \n",
       "1              0.0                               0.0  \n",
       "2              0.0                               0.0  \n",
       "3              0.0                               0.0  \n",
       "4              0.0                               0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2cc86cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1895, 22)\n",
      "(1895, 7)\n"
     ]
    }
   ],
   "source": [
    "print(route_transformed_df.shape)\n",
    "print(mtrainier_features_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa60141c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Disappointment Cleaver\n",
       "1    Disappointment Cleaver\n",
       "2    Disappointment Cleaver\n",
       "3             Little Tahoma\n",
       "4    Disappointment Cleaver\n",
       "Name: Route, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainier_features_df['Route'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8207cd",
   "metadata": {},
   "source": [
    "It matches up so we can put this back to the original dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49031eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1895, 29)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainier_features_df.reset_index(drop=True, inplace=True)\n",
    "route_transformed_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mtrainier_features_final_df = pd.concat([mtrainier_features_df, route_transformed_df], axis=1)\n",
    "mtrainier_features_final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d6654",
   "metadata": {},
   "source": [
    "mtrainier_features_final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "589d33ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Disappointment Cleaver\n",
       "1       Disappointment Cleaver\n",
       "2       Disappointment Cleaver\n",
       "3                Little Tahoma\n",
       "4       Disappointment Cleaver\n",
       "                 ...          \n",
       "1890    Disappointment Cleaver\n",
       "1891    Disappointment Cleaver\n",
       "1892    Disappointment Cleaver\n",
       "1893    Disappointment Cleaver\n",
       "1894    Disappointment Cleaver\n",
       "Name: Route, Length: 1895, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainier_features_final_df.pop('Route')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1e3221",
   "metadata": {},
   "source": [
    "This will be our final dataframe for mtrainier with the one-hot encoding features included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d7bfd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Battery Voltage AVG</th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "      <th>Curtis RIngraham Directge</th>\n",
       "      <th>Disappointment Cleaver</th>\n",
       "      <th>Emmons-Winthrop</th>\n",
       "      <th>Fuhrer's Finger</th>\n",
       "      <th>...</th>\n",
       "      <th>Mowich Face</th>\n",
       "      <th>Nisqually Glacier</th>\n",
       "      <th>Ptarmigan RIngraham Directge</th>\n",
       "      <th>Success Cleaver</th>\n",
       "      <th>Sunset RIngraham Directge</th>\n",
       "      <th>Tahoma Cleaver</th>\n",
       "      <th>Tahoma Glacier</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Wilson Headwall</th>\n",
       "      <th>glacier only - no summit attempt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.643750</td>\n",
       "      <td>26.321667</td>\n",
       "      <td>19.715000</td>\n",
       "      <td>27.839583</td>\n",
       "      <td>68.004167</td>\n",
       "      <td>88.496250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.749583</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>21.690708</td>\n",
       "      <td>2.245833</td>\n",
       "      <td>117.549667</td>\n",
       "      <td>93.660417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.461250</td>\n",
       "      <td>46.447917</td>\n",
       "      <td>27.211250</td>\n",
       "      <td>17.163625</td>\n",
       "      <td>259.121375</td>\n",
       "      <td>138.387000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.532083</td>\n",
       "      <td>40.979583</td>\n",
       "      <td>28.335708</td>\n",
       "      <td>19.591167</td>\n",
       "      <td>279.779167</td>\n",
       "      <td>176.382667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.216250</td>\n",
       "      <td>38.260417</td>\n",
       "      <td>74.329167</td>\n",
       "      <td>65.138333</td>\n",
       "      <td>264.687500</td>\n",
       "      <td>27.791292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Battery Voltage AVG  Temperature AVG  Relative Humidity AVG  \\\n",
       "0            13.643750        26.321667              19.715000   \n",
       "1            13.749583        31.300000              21.690708   \n",
       "2            13.461250        46.447917              27.211250   \n",
       "3            13.532083        40.979583              28.335708   \n",
       "4            13.216250        38.260417              74.329167   \n",
       "\n",
       "   Wind Speed Daily AVG  Wind Direction AVG  Solare Radiation AVG  \\\n",
       "0             27.839583           68.004167             88.496250   \n",
       "1              2.245833          117.549667             93.660417   \n",
       "2             17.163625          259.121375            138.387000   \n",
       "3             19.591167          279.779167            176.382667   \n",
       "4             65.138333          264.687500             27.791292   \n",
       "\n",
       "   Curtis RIngraham Directge  Disappointment Cleaver  Emmons-Winthrop  \\\n",
       "0                        0.0                     1.0              0.0   \n",
       "1                        0.0                     1.0              0.0   \n",
       "2                        0.0                     1.0              0.0   \n",
       "3                        0.0                     0.0              0.0   \n",
       "4                        0.0                     1.0              0.0   \n",
       "\n",
       "   Fuhrer's Finger  ...  Mowich Face  Nisqually Glacier  \\\n",
       "0              0.0  ...          0.0                0.0   \n",
       "1              0.0  ...          0.0                0.0   \n",
       "2              0.0  ...          0.0                0.0   \n",
       "3              0.0  ...          0.0                0.0   \n",
       "4              0.0  ...          0.0                0.0   \n",
       "\n",
       "   Ptarmigan RIngraham Directge  Success Cleaver  Sunset RIngraham Directge  \\\n",
       "0                           0.0              0.0                        0.0   \n",
       "1                           0.0              0.0                        0.0   \n",
       "2                           0.0              0.0                        0.0   \n",
       "3                           0.0              0.0                        0.0   \n",
       "4                           0.0              0.0                        0.0   \n",
       "\n",
       "   Tahoma Cleaver  Tahoma Glacier  Unknown  Wilson Headwall  \\\n",
       "0             0.0             0.0      0.0              0.0   \n",
       "1             0.0             0.0      0.0              0.0   \n",
       "2             0.0             0.0      0.0              0.0   \n",
       "3             0.0             0.0      0.0              0.0   \n",
       "4             0.0             0.0      0.0              0.0   \n",
       "\n",
       "   glacier only - no summit attempt  \n",
       "0                               0.0  \n",
       "1                               0.0  \n",
       "2                               0.0  \n",
       "3                               0.0  \n",
       "4                               0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainier_features_final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea4c871",
   "metadata": {},
   "source": [
    "Before Data Pre-Processing and splitting for validation, we should use Standard Scaling/Min Max Scaling for the numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276de71",
   "metadata": {},
   "source": [
    "In <mark>Assignment 3: Logistic Regression and SVMs</mark>, we used only standard scaling. Our end output in terms of model accuracy was affected so we will be doing different iterations of model evaluation later on: MinMax Scaling, Standard Scaling, Removing glacier only - no summit attempt, taking away the 'Route' feature entirely before feature ablation (removing all 22 one-hot encoding features), and ablating all 22 one-hot encoding features when doing feature ablation normally with the rest of the features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038896fe",
   "metadata": {},
   "source": [
    "Scaling feature transforms mtrainier_features_minmax_df even though I made a copy before scaling mtrainier_features_final_df. I could save it by using to_pickle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1668e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Battery Voltage AVG</th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "      <th>Curtis RIngraham Directge</th>\n",
       "      <th>Disappointment Cleaver</th>\n",
       "      <th>Emmons-Winthrop</th>\n",
       "      <th>Fuhrer's Finger</th>\n",
       "      <th>...</th>\n",
       "      <th>Mowich Face</th>\n",
       "      <th>Nisqually Glacier</th>\n",
       "      <th>Ptarmigan RIngraham Directge</th>\n",
       "      <th>Success Cleaver</th>\n",
       "      <th>Sunset RIngraham Directge</th>\n",
       "      <th>Tahoma Cleaver</th>\n",
       "      <th>Tahoma Glacier</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Wilson Headwall</th>\n",
       "      <th>glacier only - no summit attempt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.003522</td>\n",
       "      <td>-1.580891</td>\n",
       "      <td>-1.269311</td>\n",
       "      <td>1.895222</td>\n",
       "      <td>-0.958813</td>\n",
       "      <td>-1.567664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.506158</td>\n",
       "      <td>-1.033951</td>\n",
       "      <td>-1.180109</td>\n",
       "      <td>-0.902775</td>\n",
       "      <td>-0.414849</td>\n",
       "      <td>-1.520897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.587638</td>\n",
       "      <td>0.630261</td>\n",
       "      <td>-0.930861</td>\n",
       "      <td>0.728090</td>\n",
       "      <td>1.139477</td>\n",
       "      <td>-1.115850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.418063</td>\n",
       "      <td>0.029488</td>\n",
       "      <td>-0.880092</td>\n",
       "      <td>0.993477</td>\n",
       "      <td>1.366280</td>\n",
       "      <td>-0.771758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.066182</td>\n",
       "      <td>-0.269251</td>\n",
       "      <td>1.196481</td>\n",
       "      <td>5.972851</td>\n",
       "      <td>1.200588</td>\n",
       "      <td>-2.117412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Battery Voltage AVG  Temperature AVG  Relative Humidity AVG  \\\n",
       "0             2.003522        -1.580891              -1.269311   \n",
       "1             3.506158        -1.033951              -1.180109   \n",
       "2            -0.587638         0.630261              -0.930861   \n",
       "3             0.418063         0.029488              -0.880092   \n",
       "4            -4.066182        -0.269251               1.196481   \n",
       "\n",
       "   Wind Speed Daily AVG  Wind Direction AVG  Solare Radiation AVG  \\\n",
       "0              1.895222           -0.958813             -1.567664   \n",
       "1             -0.902775           -0.414849             -1.520897   \n",
       "2              0.728090            1.139477             -1.115850   \n",
       "3              0.993477            1.366280             -0.771758   \n",
       "4              5.972851            1.200588             -2.117412   \n",
       "\n",
       "   Curtis RIngraham Directge  Disappointment Cleaver  Emmons-Winthrop  \\\n",
       "0                        0.0                     1.0              0.0   \n",
       "1                        0.0                     1.0              0.0   \n",
       "2                        0.0                     1.0              0.0   \n",
       "3                        0.0                     0.0              0.0   \n",
       "4                        0.0                     1.0              0.0   \n",
       "\n",
       "   Fuhrer's Finger  ...  Mowich Face  Nisqually Glacier  \\\n",
       "0              0.0  ...          0.0                0.0   \n",
       "1              0.0  ...          0.0                0.0   \n",
       "2              0.0  ...          0.0                0.0   \n",
       "3              0.0  ...          0.0                0.0   \n",
       "4              0.0  ...          0.0                0.0   \n",
       "\n",
       "   Ptarmigan RIngraham Directge  Success Cleaver  Sunset RIngraham Directge  \\\n",
       "0                           0.0              0.0                        0.0   \n",
       "1                           0.0              0.0                        0.0   \n",
       "2                           0.0              0.0                        0.0   \n",
       "3                           0.0              0.0                        0.0   \n",
       "4                           0.0              0.0                        0.0   \n",
       "\n",
       "   Tahoma Cleaver  Tahoma Glacier  Unknown  Wilson Headwall  \\\n",
       "0             0.0             0.0      0.0              0.0   \n",
       "1             0.0             0.0      0.0              0.0   \n",
       "2             0.0             0.0      0.0              0.0   \n",
       "3             0.0             0.0      0.0              0.0   \n",
       "4             0.0             0.0      0.0              0.0   \n",
       "\n",
       "   glacier only - no summit attempt  \n",
       "0                               0.0  \n",
       "1                               0.0  \n",
       "2                               0.0  \n",
       "3                               0.0  \n",
       "4                               0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mtrainier_features_final_df.to_pickle(\"mtrainier_features_backup.pkl\")\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "numerical_columns = ['Battery Voltage AVG', 'Temperature AVG', 'Relative Humidity AVG',\n",
    "                      'Wind Speed Daily AVG', 'Wind Direction AVG', 'Solare Radiation AVG']\n",
    "\n",
    "mtrainier_features_final_df[numerical_columns] = standard_scaler.fit_transform(mtrainier_features_final_df[numerical_columns])\n",
    "mtrainier_features_final_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34ad1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainier_features_minmax_df = pd.read_pickle(\"mtrainier_features_backup.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14107bdd",
   "metadata": {},
   "source": [
    "I put in into a dataframe labeled minmax for scaling purposes; could possibly need to use the backup pickle file later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5d6ace7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Battery Voltage AVG</th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "      <th>Curtis RIngraham Directge</th>\n",
       "      <th>Disappointment Cleaver</th>\n",
       "      <th>Emmons-Winthrop</th>\n",
       "      <th>Fuhrer's Finger</th>\n",
       "      <th>...</th>\n",
       "      <th>Mowich Face</th>\n",
       "      <th>Nisqually Glacier</th>\n",
       "      <th>Ptarmigan RIngraham Directge</th>\n",
       "      <th>Success Cleaver</th>\n",
       "      <th>Sunset RIngraham Directge</th>\n",
       "      <th>Tahoma Cleaver</th>\n",
       "      <th>Tahoma Glacier</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Wilson Headwall</th>\n",
       "      <th>glacier only - no summit attempt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.643750</td>\n",
       "      <td>26.321667</td>\n",
       "      <td>19.715000</td>\n",
       "      <td>27.839583</td>\n",
       "      <td>68.004167</td>\n",
       "      <td>88.496250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.749583</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>21.690708</td>\n",
       "      <td>2.245833</td>\n",
       "      <td>117.549667</td>\n",
       "      <td>93.660417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.461250</td>\n",
       "      <td>46.447917</td>\n",
       "      <td>27.211250</td>\n",
       "      <td>17.163625</td>\n",
       "      <td>259.121375</td>\n",
       "      <td>138.387000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.532083</td>\n",
       "      <td>40.979583</td>\n",
       "      <td>28.335708</td>\n",
       "      <td>19.591167</td>\n",
       "      <td>279.779167</td>\n",
       "      <td>176.382667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.216250</td>\n",
       "      <td>38.260417</td>\n",
       "      <td>74.329167</td>\n",
       "      <td>65.138333</td>\n",
       "      <td>264.687500</td>\n",
       "      <td>27.791292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Battery Voltage AVG  Temperature AVG  Relative Humidity AVG  \\\n",
       "0            13.643750        26.321667              19.715000   \n",
       "1            13.749583        31.300000              21.690708   \n",
       "2            13.461250        46.447917              27.211250   \n",
       "3            13.532083        40.979583              28.335708   \n",
       "4            13.216250        38.260417              74.329167   \n",
       "\n",
       "   Wind Speed Daily AVG  Wind Direction AVG  Solare Radiation AVG  \\\n",
       "0             27.839583           68.004167             88.496250   \n",
       "1              2.245833          117.549667             93.660417   \n",
       "2             17.163625          259.121375            138.387000   \n",
       "3             19.591167          279.779167            176.382667   \n",
       "4             65.138333          264.687500             27.791292   \n",
       "\n",
       "   Curtis RIngraham Directge  Disappointment Cleaver  Emmons-Winthrop  \\\n",
       "0                        0.0                     1.0              0.0   \n",
       "1                        0.0                     1.0              0.0   \n",
       "2                        0.0                     1.0              0.0   \n",
       "3                        0.0                     0.0              0.0   \n",
       "4                        0.0                     1.0              0.0   \n",
       "\n",
       "   Fuhrer's Finger  ...  Mowich Face  Nisqually Glacier  \\\n",
       "0              0.0  ...          0.0                0.0   \n",
       "1              0.0  ...          0.0                0.0   \n",
       "2              0.0  ...          0.0                0.0   \n",
       "3              0.0  ...          0.0                0.0   \n",
       "4              0.0  ...          0.0                0.0   \n",
       "\n",
       "   Ptarmigan RIngraham Directge  Success Cleaver  Sunset RIngraham Directge  \\\n",
       "0                           0.0              0.0                        0.0   \n",
       "1                           0.0              0.0                        0.0   \n",
       "2                           0.0              0.0                        0.0   \n",
       "3                           0.0              0.0                        0.0   \n",
       "4                           0.0              0.0                        0.0   \n",
       "\n",
       "   Tahoma Cleaver  Tahoma Glacier  Unknown  Wilson Headwall  \\\n",
       "0             0.0             0.0      0.0              0.0   \n",
       "1             0.0             0.0      0.0              0.0   \n",
       "2             0.0             0.0      0.0              0.0   \n",
       "3             0.0             0.0      0.0              0.0   \n",
       "4             0.0             0.0      0.0              0.0   \n",
       "\n",
       "   glacier only - no summit attempt  \n",
       "0                               0.0  \n",
       "1                               0.0  \n",
       "2                               0.0  \n",
       "3                               0.0  \n",
       "4                               0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainier_features_minmax_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea7f3a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainier_features_minmax_df[numerical_columns] = minmax_scaler.fit_transform(mtrainier_features_minmax_df[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7d2a446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Battery Voltage AVG</th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "      <th>Curtis RIngraham Directge</th>\n",
       "      <th>Disappointment Cleaver</th>\n",
       "      <th>Emmons-Winthrop</th>\n",
       "      <th>Fuhrer's Finger</th>\n",
       "      <th>...</th>\n",
       "      <th>Mowich Face</th>\n",
       "      <th>Nisqually Glacier</th>\n",
       "      <th>Ptarmigan RIngraham Directge</th>\n",
       "      <th>Success Cleaver</th>\n",
       "      <th>Sunset RIngraham Directge</th>\n",
       "      <th>Tahoma Cleaver</th>\n",
       "      <th>Tahoma Glacier</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Wilson Headwall</th>\n",
       "      <th>glacier only - no summit attempt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.813017</td>\n",
       "      <td>0.395119</td>\n",
       "      <td>0.083886</td>\n",
       "      <td>0.427392</td>\n",
       "      <td>0.204255</td>\n",
       "      <td>0.240442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.944215</td>\n",
       "      <td>0.496061</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.034478</td>\n",
       "      <td>0.389892</td>\n",
       "      <td>0.254473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.586777</td>\n",
       "      <td>0.803203</td>\n",
       "      <td>0.169424</td>\n",
       "      <td>0.263495</td>\n",
       "      <td>0.920335</td>\n",
       "      <td>0.375994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.674587</td>\n",
       "      <td>0.692326</td>\n",
       "      <td>0.182255</td>\n",
       "      <td>0.300762</td>\n",
       "      <td>0.997736</td>\n",
       "      <td>0.479228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.283058</td>\n",
       "      <td>0.637191</td>\n",
       "      <td>0.707076</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941191</td>\n",
       "      <td>0.075508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Battery Voltage AVG  Temperature AVG  Relative Humidity AVG  \\\n",
       "0             0.813017         0.395119               0.083886   \n",
       "1             0.944215         0.496061               0.106431   \n",
       "2             0.586777         0.803203               0.169424   \n",
       "3             0.674587         0.692326               0.182255   \n",
       "4             0.283058         0.637191               0.707076   \n",
       "\n",
       "   Wind Speed Daily AVG  Wind Direction AVG  Solare Radiation AVG  \\\n",
       "0              0.427392            0.204255              0.240442   \n",
       "1              0.034478            0.389892              0.254473   \n",
       "2              0.263495            0.920335              0.375994   \n",
       "3              0.300762            0.997736              0.479228   \n",
       "4              1.000000            0.941191              0.075508   \n",
       "\n",
       "   Curtis RIngraham Directge  Disappointment Cleaver  Emmons-Winthrop  \\\n",
       "0                        0.0                     1.0              0.0   \n",
       "1                        0.0                     1.0              0.0   \n",
       "2                        0.0                     1.0              0.0   \n",
       "3                        0.0                     0.0              0.0   \n",
       "4                        0.0                     1.0              0.0   \n",
       "\n",
       "   Fuhrer's Finger  ...  Mowich Face  Nisqually Glacier  \\\n",
       "0              0.0  ...          0.0                0.0   \n",
       "1              0.0  ...          0.0                0.0   \n",
       "2              0.0  ...          0.0                0.0   \n",
       "3              0.0  ...          0.0                0.0   \n",
       "4              0.0  ...          0.0                0.0   \n",
       "\n",
       "   Ptarmigan RIngraham Directge  Success Cleaver  Sunset RIngraham Directge  \\\n",
       "0                           0.0              0.0                        0.0   \n",
       "1                           0.0              0.0                        0.0   \n",
       "2                           0.0              0.0                        0.0   \n",
       "3                           0.0              0.0                        0.0   \n",
       "4                           0.0              0.0                        0.0   \n",
       "\n",
       "   Tahoma Cleaver  Tahoma Glacier  Unknown  Wilson Headwall  \\\n",
       "0             0.0             0.0      0.0              0.0   \n",
       "1             0.0             0.0      0.0              0.0   \n",
       "2             0.0             0.0      0.0              0.0   \n",
       "3             0.0             0.0      0.0              0.0   \n",
       "4             0.0             0.0      0.0              0.0   \n",
       "\n",
       "   glacier only - no summit attempt  \n",
       "0                               0.0  \n",
       "1                               0.0  \n",
       "2                               0.0  \n",
       "3                               0.0  \n",
       "4                               0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainier_features_minmax_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a4706a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainier_features_default_df = pd.read_pickle(\"mtrainier_features_backup.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29c3f85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Battery Voltage AVG</th>\n",
       "      <th>Temperature AVG</th>\n",
       "      <th>Relative Humidity AVG</th>\n",
       "      <th>Wind Speed Daily AVG</th>\n",
       "      <th>Wind Direction AVG</th>\n",
       "      <th>Solare Radiation AVG</th>\n",
       "      <th>Curtis RIngraham Directge</th>\n",
       "      <th>Disappointment Cleaver</th>\n",
       "      <th>Emmons-Winthrop</th>\n",
       "      <th>Fuhrer's Finger</th>\n",
       "      <th>...</th>\n",
       "      <th>Mowich Face</th>\n",
       "      <th>Nisqually Glacier</th>\n",
       "      <th>Ptarmigan RIngraham Directge</th>\n",
       "      <th>Success Cleaver</th>\n",
       "      <th>Sunset RIngraham Directge</th>\n",
       "      <th>Tahoma Cleaver</th>\n",
       "      <th>Tahoma Glacier</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Wilson Headwall</th>\n",
       "      <th>glacier only - no summit attempt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.643750</td>\n",
       "      <td>26.321667</td>\n",
       "      <td>19.715000</td>\n",
       "      <td>27.839583</td>\n",
       "      <td>68.004167</td>\n",
       "      <td>88.496250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.749583</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>21.690708</td>\n",
       "      <td>2.245833</td>\n",
       "      <td>117.549667</td>\n",
       "      <td>93.660417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.461250</td>\n",
       "      <td>46.447917</td>\n",
       "      <td>27.211250</td>\n",
       "      <td>17.163625</td>\n",
       "      <td>259.121375</td>\n",
       "      <td>138.387000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.532083</td>\n",
       "      <td>40.979583</td>\n",
       "      <td>28.335708</td>\n",
       "      <td>19.591167</td>\n",
       "      <td>279.779167</td>\n",
       "      <td>176.382667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.216250</td>\n",
       "      <td>38.260417</td>\n",
       "      <td>74.329167</td>\n",
       "      <td>65.138333</td>\n",
       "      <td>264.687500</td>\n",
       "      <td>27.791292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Battery Voltage AVG  Temperature AVG  Relative Humidity AVG  \\\n",
       "0            13.643750        26.321667              19.715000   \n",
       "1            13.749583        31.300000              21.690708   \n",
       "2            13.461250        46.447917              27.211250   \n",
       "3            13.532083        40.979583              28.335708   \n",
       "4            13.216250        38.260417              74.329167   \n",
       "\n",
       "   Wind Speed Daily AVG  Wind Direction AVG  Solare Radiation AVG  \\\n",
       "0             27.839583           68.004167             88.496250   \n",
       "1              2.245833          117.549667             93.660417   \n",
       "2             17.163625          259.121375            138.387000   \n",
       "3             19.591167          279.779167            176.382667   \n",
       "4             65.138333          264.687500             27.791292   \n",
       "\n",
       "   Curtis RIngraham Directge  Disappointment Cleaver  Emmons-Winthrop  \\\n",
       "0                        0.0                     1.0              0.0   \n",
       "1                        0.0                     1.0              0.0   \n",
       "2                        0.0                     1.0              0.0   \n",
       "3                        0.0                     0.0              0.0   \n",
       "4                        0.0                     1.0              0.0   \n",
       "\n",
       "   Fuhrer's Finger  ...  Mowich Face  Nisqually Glacier  \\\n",
       "0              0.0  ...          0.0                0.0   \n",
       "1              0.0  ...          0.0                0.0   \n",
       "2              0.0  ...          0.0                0.0   \n",
       "3              0.0  ...          0.0                0.0   \n",
       "4              0.0  ...          0.0                0.0   \n",
       "\n",
       "   Ptarmigan RIngraham Directge  Success Cleaver  Sunset RIngraham Directge  \\\n",
       "0                           0.0              0.0                        0.0   \n",
       "1                           0.0              0.0                        0.0   \n",
       "2                           0.0              0.0                        0.0   \n",
       "3                           0.0              0.0                        0.0   \n",
       "4                           0.0              0.0                        0.0   \n",
       "\n",
       "   Tahoma Cleaver  Tahoma Glacier  Unknown  Wilson Headwall  \\\n",
       "0             0.0             0.0      0.0              0.0   \n",
       "1             0.0             0.0      0.0              0.0   \n",
       "2             0.0             0.0      0.0              0.0   \n",
       "3             0.0             0.0      0.0              0.0   \n",
       "4             0.0             0.0      0.0              0.0   \n",
       "\n",
       "   glacier only - no summit attempt  \n",
       "0                               0.0  \n",
       "1                               0.0  \n",
       "2                               0.0  \n",
       "3                               0.0  \n",
       "4                               0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainier_features_default_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30594c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainier_no_route_df = mtrainier_features_final_df.iloc[:, 0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d129f3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Battery Voltage AVG', 'Temperature AVG', 'Relative Humidity AVG',\n",
       "       'Wind Speed Daily AVG', 'Wind Direction AVG', 'Solare Radiation AVG',\n",
       "       'Curtis RIngraham Directge', 'Disappointment Cleaver',\n",
       "       'Emmons-Winthrop', 'Fuhrer's Finger', 'Fuhrers Finger',\n",
       "       'Gibralter Chute', 'Gibralter Ledges', 'Ingraham Direct',\n",
       "       'Kautz Cleaver', 'Kautz Glacier', 'Liberty RIngraham Directge',\n",
       "       'Little Tahoma', 'Mowich Face', 'Nisqually Glacier',\n",
       "       'Ptarmigan RIngraham Directge', 'Success Cleaver',\n",
       "       'Sunset RIngraham Directge', 'Tahoma Cleaver', 'Tahoma Glacier',\n",
       "       'Unknown', 'Wilson Headwall', 'glacier only - no summit attempt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainier_features_default_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "289b7cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 1.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(mtrainier_features_default_df['Unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c899492c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.999472\n",
       "1.0    0.000528\n",
       "Name: Unknown, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainier_features_default_df['Unknown'].value_counts(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26302a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.986807\n",
       "1.0    0.013193\n",
       "Name: glacier only - no summit attempt, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtrainier_features_default_df['glacier only - no summit attempt'].value_counts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362e033e",
   "metadata": {},
   "source": [
    "It seems like these columns for route - one-hot encodings were meant to be unsuccessful which thus makes prediction accuracy hard for models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6544178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrainier_removed_df = mtrainier_features_final_df.drop(columns=['Unknown', 'glacier only - no summit attempt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b5a9e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e5139f",
   "metadata": {},
   "source": [
    "To make things less confusing, I will be putting all the dataframes and files that we will use later right here. \n",
    "\n",
    "- **mtrainier_labels_df** &harr; (Labels from original mtrainier_df[\"Succeeded\"])\n",
    "- **mtrainier_features_df** &harr; (Features from original mtrainier_df without one-hot encoding for \"Route\")\n",
    "- **mtrainier_features_final_df**  &harr; (Features that have one-hot encoding applied + Standard Scaling)\n",
    "- **mtrainier_features_minmax_df**  &harr; (Features that have one-hot encoding applied + MinMax Scaling)\n",
    "- **mtrainier_features_default_df**  &harr; (Features that have one-hot encoding applied - no scaling)\n",
    "- **mtrainier_features_backup.pkl**  &harr; (Backup pkl file that saved mtrainier_features_final_df before Standard Scaling) \n",
    "- **mtrainier_no_route_df** &harr; (Features without \"Route\" + Standard Scaling)\n",
    "- **mtrainier_removed_df** &harr; (Features without \"glacier only - no summit attempt\" and \"Unknown\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c711328e",
   "metadata": {},
   "source": [
    "## 2. Defining Classifiers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f912572",
   "metadata": {},
   "source": [
    "In Assignment 3, I used code from Lab 5 which I will now be updating with code from my submission of Lab 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5aa2b949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are working with classifiers dict_keys(['lr', 'svm', 'decision_tree', 'random_forest', 'grad_boost', 'voting'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "#Ensemble methods try to combine multiple models to improve accuracy. \n",
    "\n",
    "\n",
    "lr_vanilla = LogisticRegression(penalty= \"none\")  #penalty=\"none\" depending on your sklearn version\n",
    "svm_linear = SVC(kernel=\"linear\")\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier(random_state=23) # some random seed for reproducibility\n",
    "grad_boost = GradientBoostingClassifier()\n",
    "voting = VotingClassifier(estimators=[(\"1\",lr_vanilla),(\"2\",svm_linear),(\"3\",dt)])\n",
    "\n",
    "all_models = {\"lr\":lr_vanilla, \n",
    "              \"svm\":svm_linear,\n",
    "              \"decision_tree\":dt,\n",
    "              \"random_forest\":rf,\n",
    "              \"grad_boost\":grad_boost,\n",
    "              \"voting\":voting}\n",
    "\n",
    "print (f\"We are working with classifiers {all_models.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea079c73",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372b50a",
   "metadata": {},
   "source": [
    "From earlier, I expressed my interest in tinkering around with modifying the dataframe to see if I could approve accuracy in model prediction. \n",
    "\\\n",
    "\\\n",
    "For reference:\n",
    "1. Standard Scaling\n",
    "2. MinMax Scaling\n",
    "3. Removing \"glacier only - no summit attempt\" and \"Unknown\" (Both of these features equate to an almost 100% non success rate for climbing Mt. Rainier)\n",
    "4. Taking away the 'Route' feature entirely before feature ablation (removing all 22 one-hot encoding features)\n",
    "5. Feature Ablation for all 22 one-hot encoding features when doing feature ablation normally with the rest of the features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcae28f5",
   "metadata": {},
   "source": [
    "## Data Splitting and Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f2f7e7",
   "metadata": {},
   "source": [
    "### 1. Let's Start with Standard Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ff7b895",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation accuracy for model lr = 0.6293257653938769\n",
      "Mean cross validation accuracy for model svm = 0.6175988992088064\n",
      "Mean cross validation accuracy for model decision_tree = 0.6076298589611283\n",
      "Mean cross validation accuracy for model random_forest = 0.634031647746818\n",
      "Mean cross validation accuracy for model grad_boost = 0.6340591675266598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation accuracy for model voting = 0.6328551771585827\n",
      "Best model is grad_boost with 10-fold accuracy of 0.6340591675266598\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "features = mtrainier_features_final_df.to_numpy()\n",
    "labels = mtrainier_labels_df.to_numpy()\n",
    "\n",
    "_x, x_test, _y, y_test = train_test_split(features, labels, test_size=0.10, random_state=42)\n",
    "\n",
    "k = 10\n",
    "\n",
    "# We can use sklearn's cross validation score directly\n",
    "# We can speed up training using n_jobs parameter which specifies how many cpu_cores to use\n",
    "\n",
    "best_model_name = \"\"\n",
    "best_model_valid_accuracy = 0\n",
    "best_model = \"None\"\n",
    "\n",
    "for model_name in all_models.keys():\n",
    "    model = all_models[model_name]\n",
    "    cv_scores = cross_val_score(model,_x,_y.flatten(), cv=k, n_jobs=4)\n",
    "    average_cv_score = cv_scores.mean()\n",
    "    print (f\"Mean cross validation accuracy for model {model_name} = {average_cv_score}\")\n",
    "\n",
    "    if average_cv_score > best_model_valid_accuracy :\n",
    "        best_model_name = model_name\n",
    "        best_model_valid_accuracy  = average_cv_score\n",
    "        best_model = model\n",
    "\n",
    "print (f\"Best model is {best_model_name} with {k}-fold accuracy of {best_model_valid_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04dcc10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for model 0.6263157894736842\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Let's fit the best model again with train+valid data\n",
    "# This is the model we are gonna ship/deploy to practice\n",
    "\n",
    "best_model.fit(_x,_y.flatten())\n",
    "\n",
    "y_pred_test = best_model.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_pred_test, y_test.flatten())\n",
    "\n",
    "print (f\"Test accuracy for model {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03eb235",
   "metadata": {},
   "source": [
    "For Standard Scaling, the best model is <mark> **grad_boost** with 10-fold accuracy of **0.6340591675266597** and test accuracy for model **0.6263157894736842** </mark>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bac661",
   "metadata": {},
   "source": [
    "###  For Standard Scaling, we will run feature abalation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71393340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Battery Voltage AVG', 'Temperature AVG', 'Relative Humidity AVG',\n",
      "       'Wind Speed Daily AVG', 'Wind Direction AVG', 'Solare Radiation AVG',\n",
      "       'Curtis RIngraham Directge', 'Disappointment Cleaver',\n",
      "       'Emmons-Winthrop', 'Fuhrer's Finger', 'Fuhrers Finger',\n",
      "       'Gibralter Chute', 'Gibralter Ledges', 'Ingraham Direct',\n",
      "       'Kautz Cleaver', 'Kautz Glacier', 'Liberty RIngraham Directge',\n",
      "       'Little Tahoma', 'Mowich Face', 'Nisqually Glacier',\n",
      "       'Ptarmigan RIngraham Directge', 'Success Cleaver',\n",
      "       'Sunset RIngraham Directge', 'Tahoma Cleaver', 'Tahoma Glacier',\n",
      "       'Unknown', 'Wilson Headwall', 'glacier only - no summit attempt'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "feature_names = mtrainier_features_final_df.columns \n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c20b230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Curtis RIngraham Directge', 'Disappointment Cleaver',\n",
       "       'Emmons-Winthrop', 'Fuhrer's Finger', 'Fuhrers Finger',\n",
       "       'Gibralter Chute', 'Gibralter Ledges', 'Ingraham Direct',\n",
       "       'Kautz Cleaver', 'Kautz Glacier', 'Liberty RIngraham Directge',\n",
       "       'Little Tahoma', 'Mowich Face', 'Nisqually Glacier',\n",
       "       'Ptarmigan RIngraham Directge', 'Success Cleaver',\n",
       "       'Sunset RIngraham Directge', 'Tahoma Cleaver', 'Tahoma Glacier',\n",
       "       'Unknown', 'Wilson Headwall', 'glacier only - no summit attempt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[6:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71401933",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ablated = np.delete(_x,np.s_[6:28],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8480475",
   "metadata": {},
   "source": [
    "We want to remove all the routes when trying to remove a categorical column from \"Route\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2817b96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature Battery Voltage AVG\n",
      "Mean cross validation accuracy = 0.6352356381148951\n",
      "Removing feature Temperature AVG\n",
      "Mean cross validation accuracy = 0.6440282077743378\n",
      "Removing feature Relative Humidity AVG\n",
      "Mean cross validation accuracy = 0.6334640522875817\n",
      "Removing feature Wind Speed Daily AVG\n",
      "Mean cross validation accuracy = 0.6352287581699347\n",
      "Removing feature Wind Direction AVG\n",
      "Mean cross validation accuracy = 0.6399312005503957\n",
      "Removing feature Solare Radiation AVG\n",
      "Mean cross validation accuracy = 0.6399346405228759\n",
      "Removing feature Curtis RIngraham Directge\n",
      "Mean cross validation accuracy = 0.6264396284829722\n"
     ]
    }
   ],
   "source": [
    "# Let's run ablation tests on our best model\n",
    "# You could choose any model to do this test\n",
    "best_model = GradientBoostingClassifier()\n",
    "\n",
    "feature_names = mtrainier_features_final_df.columns \n",
    "\n",
    "# Let's maintain an accuracy dictionary\n",
    "\n",
    "accuracy_drop_log = {\"No ablation\":0}\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    # we are going to drop one feature at a time - which includes the entire one-hot encoding key when we do route\n",
    "    feature_name = feature_names[i]\n",
    "    print (f\"Removing feature {feature_name}\")\n",
    "    \n",
    "    #first categorical feature derived from one-hot encoding\n",
    "    if feature_name != 'Curtis RIngraham Directge': \n",
    "        x_ablated = np.delete(_x,i,axis=1) \n",
    "        cv_scores = cross_val_score(best_model,x_ablated,_y.flatten(), cv=k, n_jobs=4)\n",
    "        average_cv_score = cv_scores.mean()\n",
    "        print (f\"Mean cross validation accuracy = {average_cv_score}\")\n",
    "        accuracy_drop_log[feature_name] = best_model_valid_accuracy-average_cv_score\n",
    "    else: #to represent all the routes \n",
    "        x_ablated = np.delete(_x,np.s_[6:28],axis=1)\n",
    "        cv_scores = cross_val_score(best_model,x_ablated,_y.flatten(), cv=k, n_jobs=4)\n",
    "        average_cv_score = cv_scores.mean()\n",
    "        print (f\"Mean cross validation accuracy = {average_cv_score}\")\n",
    "        accuracy_drop_log[feature_name] = best_model_valid_accuracy-average_cv_score\n",
    "        break \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18da48ba",
   "metadata": {},
   "source": [
    "By seperating the categorical features through an if/else statement, we can break the loop off and delete all the categorical features in one go. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1273c6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 8 artists>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7],\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAFzCAYAAADGyoWFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA6FklEQVR4nO3deZhkZXn+8e8NyOLCJgMiu2TQDEZBhsWoGAUUVAS3AGJAkoioqNGowbigxsQl0fyiIopGBIMgSBQ0GDYFo4AwwyogMoCGESKIiigIDt6/P963Zqp7qpcz3dQ51d6f66qr65yqU/1UTU8957zL88o2ERERTazWdgARETF6kjwiIqKxJI+IiGgsySMiIhpL8oiIiMbWaDuAYdloo4289dZbtx1GRMRIWbx48c9szxu//w8meWy99dYsWrSo7TAiIkaKpB8P2p9mq4iIaCzJIyIiGkvyiIiIxpI8IiKisSSPiIhoLMkjIiIam5XkIWlvSTdIWiLpqAGPS9LH6uNXS3rKVMdK+pKkK+vtR5KurPu3lnRf32Ofmo33EBER0zfjeR6SVgeOAfYClgKXSTrT9nV9T9sHmF9vuwLHArtOdqztA/p+x0eAu/te7ybbO8w09oiIWDWzMUlwF2CJ7ZsBJJ0C7Af0J4/9gBNdFg+5RNL6kjYFtp7qWEkC/hx49izEGhExUt4rzej4ox+iNZtmo9lqM+DWvu2ldd90njOdY58B/NT2jX37tpF0haQLJT1jJsFHRERzs3HlMSgtjk91Ez1nOsceBJzct307sKXtuyTtBHxV0va2f7VSYNLhwOEAW2655QThR0REU7Nx5bEU2KJve3Pgtmk+Z9JjJa0BvBj4Um+f7ftt31XvLwZuArYbFJjt42wvtL1w3ryV6npFRMQqmo3kcRkwX9I2ktYEDgTOHPecM4FD6qir3YC7bd8+jWP3BH5ge2lvh6R5taMdSY+jdMLfPAvvIyIipmnGzVa2l0k6EjgbWB34nO1rJR1RH/8UcBbwPGAJcC9w2GTH9r38gYxtsgLYHXifpGXAg8ARtn8+0/cRERHTJz9EPfFds3DhQqcke0SMmrZHW0labHvh+P2ZYR4REY0leURERGNJHhER0ViSR0RENJbkERERjSV5REREY0keERHRWJJHREQ0luQRERGNJXlERERjSR4REdFYkkdERDSW5BEREY0leURERGNJHhER0ViSR0RENJbkERERjSV5REREY0keERHRWJJHREQ0NivJQ9Lekm6QtETSUQMel6SP1cevlvSUqY6V9B5JP5F0Zb09r++xt9fn3yDpubPxHiIiYvrWmOkLSFodOAbYC1gKXCbpTNvX9T1tH2B+ve0KHAvsOo1j/9X2v4z7fQuAA4HtgccC50nazvaDM30vERExPbNx5bELsMT2zbYfAE4B9hv3nP2AE11cAqwvadNpHjvefsAptu+3fQuwpL5OREQMyWwkj82AW/u2l9Z903nOVMceWZu5Pidpgwa/DwBJh0taJGnRnXfeOd33ExERU5iN5KEB+zzN50x27LHAtsAOwO3ARxr8vrLTPs72QtsL582bN+gpERGxCmbc50E589+ib3tz4LZpPmfNiY61/dPeTkmfAb7e4PdFRMRDaDauPC4D5kvaRtKalM7sM8c950zgkDrqajfgbtu3T3Zs7RPpeRHw/b7XOlDSWpK2oXTCXzoL7yMiIqZpxlcetpdJOhI4G1gd+JztayUdUR//FHAW8DxK5/a9wGGTHVtf+sOSdqA0Sf0IeHU95lpJpwLXAcuA12WkVUTEcMke2F0w5yxcuNCLFi1qO4yIiEbeq0HdvNN39Ay/4yUttr1w/P7MMI+IiMaSPCIiorEkj4iIaCzJIyIiGkvyiIiIxpI8IiKisSSPiIhoLMkjIiIaS/KIiIjGkjwiIqKxJI+IiGgsySMiIhpL8oiIiMaSPCIiorEkj4iIaCzJIyIiGkvyiIiIxpI8IiKisSSPiIhobFaSh6S9Jd0gaYmkowY8Lkkfq49fLekpUx0r6Z8l/aA+/yuS1q/7t5Z0n6Qr6+1Ts/EeIiJi+macPCStDhwD7AMsAA6StGDc0/YB5tfb4cCx0zj2XOCJtp8E/BB4e9/r3WR7h3o7YqbvISIimpmNK49dgCW2b7b9AHAKsN+45+wHnOjiEmB9SZtOdqztc2wvq8dfAmw+C7FGRMQsmI3ksRlwa9/20rpvOs+ZzrEAfwl8o297G0lXSLpQ0jMmCkzS4ZIWSVp05513Tv1OIiJiWmYjeWjAPk/zOVMeK+kdwDLgpLrrdmBL2zsCbwa+KGndQYHZPs72QtsL582bN8lbiIiIJtaYhddYCmzRt705cNs0n7PmZMdKOhR4AbCHbQPYvh+4v95fLOkmYDtg0Sy8l4iImIbZuPK4DJgvaRtJawIHAmeOe86ZwCF11NVuwN22b5/sWEl7A38HvND2vb0XkjSvdrQj6XGUTvibZ+F9RETENM34ysP2MklHAmcDqwOfs32tpCPq458CzgKeBywB7gUOm+zY+tKfANYCzpUEcEkdWbU78D5Jy4AHgSNs/3ym7yMiIqZPtTVozlu4cKEXLUrLVkSMlvdqUNfw9B09w+94SYttLxy/PzPMIyKisSSPiIhoLMkjIiIaS/KIiIjGkjwiIqKxJI+IiGgsySMiIhpL8oiIiMaSPCIiorEkj4iIaCzJIyIiGkvyiIiIxpI8IiKisSSPiIhoLMkjIiIam41laCPmjJmunQAzXz8hYhTkyiMiIhpL8oiIiMaSPCIiorFZSR6S9pZ0g6Qlko4a8Lgkfaw+frWkp0x1rKQNJZ0r6cb6c4O+x95en3+DpOfOxnuIiIjpm3HykLQ6cAywD7AAOEjSgnFP2weYX2+HA8dO49ijgPNtzwfOr9vUxw8Etgf2Bj5ZXyciIoZkNq48dgGW2L7Z9gPAKcB+456zH3Cii0uA9SVtOsWx+wEn1PsnAPv37T/F9v22bwGW1NeJiIghmY2hupsBt/ZtLwV2ncZzNpvi2E1s3w5g+3ZJG/e91iUDXmslkg6nXOmw5ZZbTvPtjKZRGGI6CjGOwjDbUfgcYeZxJsbh/Y5VMRtXHoM+/fHvdqLnTOfYVfl9Zad9nO2FthfOmzdvipeNiIjpmo3ksRTYom97c+C2aT5nsmN/Wpu2qD/vaPD7IiLiITQbyeMyYL6kbSStSenMPnPcc84EDqmjrnYD7q5NUpMdeyZwaL1/KHBG3/4DJa0laRtKJ/yls/A+IiJimmbc52F7maQjgbOB1YHP2b5W0hH18U8BZwHPo3Ru3wscNtmx9aU/CJwq6a+A/wVeVo+5VtKpwHXAMuB1th+c6fuIiIjpm5XaVrbPoiSI/n2f6rtv4HXTPbbuvwvYY4Jj/hH4xxmEHBERM5AZ5hER0ViSR0RENJbkERERjSV5REREY0keERHRWJJHREQ0luQRERGNZQ3zOaKrxdNi9uXfOrogVx4REdFYkkdERDSW5BEREY0leURERGNJHhER0ViSR0RENJbkERERjSV5REREY0keERHRWJJHREQ0luQRERGNzSh5SNpQ0rmSbqw/N5jgeXtLukHSEklHTXW8pL0kLZZ0Tf357L5jLqivdWW9bTyT9xAREc3N9MrjKOB82/OB8+v2GJJWB44B9gEWAAdJWjDF8T8D9rX9J8ChwBfGvezBtneotztm+B4iIqKhmSaP/YAT6v0TgP0HPGcXYIntm20/AJxSj5vweNtX2L6t7r8WWFvSWjOMNSIiZslMk8cmtm8HqD8HNSFtBtzat7207pvu8S8BrrB9f9++42uT1bskaaLgJB0uaZGkRXfeeef031VERExqyvU8JJ0HPGbAQ++Y5u8Y9OU+rQUJJG0PfAh4Tt/ug23/RNKjgNOBvwBOHHS87eOA4wAWLlyYRRAiImbJlMnD9p4TPSbpp5I2tX27pE2BQf0PS4Et+rY3B3pNUhMeL2lz4CvAIbZv6ovnJ/XnPZK+SGkWG5g8IiLioTHTZqszKR3a1J9nDHjOZcB8SdtIWhM4sB434fGS1gf+C3i77e/2XkjSGpI2qvcfBrwA+P4M30NERDQ00+TxQWAvSTcCe9VtJD1W0lkAtpcBRwJnA9cDp9q+drLj6/P/CHjXuCG5awFnS7oauBL4CfCZGb6HiIhoaEZrmNu+C9hjwP7bgOf1bZ8FnNXg+PcD75/g1+60qvFGRMTsyAzziIhoLMkjIiIaS/KIiIjGkjwiIqKxJI+IiGgsySMiIhpL8oiIiMaSPCIiorEkj4iIaCzJIyIiGkvyiIiIxpI8IiKisSSPiIhoLMkjIiIaS/KIiIjGkjwiIqKxJI+IiGgsySMiIhpL8oiIiMZmlDwkbSjpXEk31p8bTPC8vSXdIGmJpKOmOl7S1pLuk3RlvX2q75idJF1TX+tjkjST9xAREc3N9MrjKOB82/OB8+v2GJJWB44B9gEWAAdJWjCN42+yvUO9HdG3/1jgcGB+ve09w/cQERENzTR57AecUO+fAOw/4Dm7AEts32z7AeCUetx0j19O0qbAurYvtm3gxKmOiYiI2TfT5LGJ7dsB6s+NBzxnM+DWvu2ldd9Ux28j6QpJF0p6Rt9rLZ3gtVYi6XBJiyQtuvPOO5u8r4iImMQaUz1B0nnAYwY89I5p/o5BfRKe4pjbgS1t3yVpJ+CrkrZv+lq2jwOOA1i4cOFUvzMiIqZpyuRhe8+JHpP0U0mb2r69NindMeBpS4Et+rY3B26r9wceb/t+4P56f7Gkm4Dt6mttPsFrRUTEkMy02epM4NB6/1DgjAHPuQyYL2kbSWsCB9bjJjxe0rza0Y6kx1E6xm+uTVv3SNqtjrI6ZILfGRERD6GZJo8PAntJuhHYq24j6bGSzgKwvQw4EjgbuB441fa1kx0P7A5cLekq4MvAEbZ/Xh97DfBZYAlwE/CNGb6HiIhoaMpmq8nYvgvYY8D+24Dn9W2fBZzV4PjTgdMn+J2LgCeuetQRETFTmWEeERGNJXlERERjSR4REdFYkkdERDQ2ow7ziIiJHO3uz8sdhRi7KlceERHRWJJHREQ0luQRERGNJXlERERjSR4REdFYkkdERDSW5BEREY0leURERGNJHhER0ViSR0RENJbkERERjSV5REREY0keERHRWJJHREQ0NqPkIWlDSedKurH+3GCC5+0t6QZJSyQdNdXxkg6WdGXf7feSdqiPXVBfq/fYxjN5DxER0dxMrzyOAs63PR84v26PIWl14BhgH2ABcJCkBZMdb/sk2zvY3gH4C+BHtq/se9mDe4/bvmOG7yEiIhqaafLYDzih3j8B2H/Ac3YBlti+2fYDwCn1uOkefxBw8gzjjIiIWTTT5LGJ7dsB6s9BTUibAbf2bS+t+6Z7/AGsnDyOr01W75KkiYKTdLikRZIW3XnnndN7RxERMaUpl6GVdB7wmAEPvWOav2PQl/u01n6UtCtwr+3v9+0+2PZPJD0KOJ3SrHXioONtHwccB7Bw4cKsNxkRMUumTB6295zoMUk/lbSp7dslbQoM6n9YCmzRt705cFu9P9XxBzLuqsP2T+rPeyR9kdIsNjB5RETEQ2OmzVZnAofW+4cCZwx4zmXAfEnbSFqTkhDOnOp4SasBL6P0kfT2rSFpo3r/YcALgP6rkoiIGIKZJo8PAntJuhHYq24j6bGSzgKwvQw4EjgbuB441fa1kx1f7Q4stX1z3761gLMlXQ1cCfwE+MwM30NERDQ0ZbPVZGzfBewxYP9twPP6ts8Czpru8fWxC4Ddxu37DbDTTGKOiIiZywzziIhoLMkjIiIaS/KIiIjGkjwiIqKxJI+IiGgsySMiIhpL8oiIiMaSPCIiorEkj4iIaCzJIyIiGkvyiIiIxpI8IiKisSSPiIhoLMkjIiIaS/KIiIjGkjwiIqKxJI+IiGgsySMiIhpL8oiIiMZmlDwkbSjpXEk31p8bTPC8vSXdIGmJpKP69r9M0rWSfi9p4bhj3l6ff4Ok5/bt30nSNfWxj0nSTN5DREQ0N9Mrj6OA823PB86v22NIWh04BtgHWAAcJGlBffj7wIuBb487ZgFwILA9sDfwyfo6AMcChwPz623vGb6HiIhoaKbJYz/ghHr/BGD/Ac/ZBVhi+2bbDwCn1OOwfb3tGyZ43VNs32/7FmAJsIukTYF1bV9s28CJE/zOiIh4CK0xw+M3sX07gO3bJW084DmbAbf2bS8Fdp3idTcDLhl3zGbA7+r98fsHknQ45SqFLbfccopfGQ+1o+22Q4iIWTJl8pB0HvCYAQ+9Y5q/Y1CfxFTfIhMd0+i1bB8HHAewcOHCfHNFRMySKZOH7T0nekzSTyVtWq86NgXuGPC0pcAWfdubA7dN8WsnOmZpvd/ktSIiYpbNtM/jTODQev9Q4IwBz7kMmC9pG0lrUjrCz5zG6x4oaS1J21A6xi+tTWT3SNqtjrI6ZILfGRERD6GZJo8PAntJuhHYq24j6bGSzgKwvQw4EjgbuB441fa19XkvkrQUeCrwX5LOrsdcC5wKXAf8N/A62w/W3/ka4LOUTvSbgG/M8D1ERERD8h9IJ+bChQu9aNGitsOIiBgpkhbbXjh+f2aYR0REY0keERHRWJJHREQ0luQRERGN/cF0mEu6E/jxQ/TyGwE/e4hee7YkxtkzCnEmxtmRGGEr2/PG7/yDSR4PJUmLBo1G6JLEOHtGIc7EODsS48TSbBUREY0leURERGNJHrPjuLYDmIbEOHtGIc7EODsS4wTS5xEREY3lyiMiIhpL8oiIiMaSPCIiorGZLkP7B0vSZsBW9H2Gtr/dXkSFpO2BbW2fWbf/FVivPvwJ25e3FtyIkbQfsLntY+r294DeZKm32f5ya8FVklYH1rH967q9G7BmffgK2/e0Flwl6enA42yfWLe/DGxYH36/7W+2Flw1CjH2q/HOt328pHnAI23fMtQY0mHenKQPAQdQ1hvprTNi2y9sL6pC0teAD9i+qG5fB7wLeDjwEtv7txgeAJL+CtjQ9j/X7Z8Aj6IsM/w228e2GV+PpO8CB9q+tW5fCewBPAI43vYeLYYHgKR/Ae6w/eG6fQvwfWBt4HLbf9dmfACSzgdeb/u6un0N8ErK5/j3tvduMTxgNGLskXQ0sBB4vO3tJD0WOM3204YZR648Vs3+lH+4+9sOZIBNe4mj+pXt0wEkvbqlmMY7Auj/z3iH7c0krQ2cA3QieQBr9hJH9R3bdwF3SXpEW0GNswewc9/2L23vW1fa/J+WYhpv3d6XcnWj7cUAkj7QUkzjjUKMPS8CdgQuB7B9m6RHDTuI9HmsmpuBh7UdxATG/BHZ3q1vc+MhxzKR1eqXcM9pALZ/C6zTTkgDbdC/YfvIvs2Vav20ZLW6WmfP30G5DAYe2U5IK1m/f8P2i/s2NxluKBNav3+jozH2PFD/fQ3Q1olMksequRe4UtKnJX2sd2s7qOo2SbuO31nbwm9rIZ5B1uvfsP1PAJJWAx7dSkSDfU/Sq8bvrFdwl7YQzyBr9p912j4HQNJ6lKarLviBpOeP3ynpBcANLcQzyCjE2HOqpE8D69e/z/OAzww7iPR5rAJJhw7ab/uEYccynqRdgC8Bn6de1gI7AYcCB9hu/UtP0ieBn9t+57j97wc2sn1EO5GNJWlj4KvA/Yz9LNcC9rf905ZCW07Sm4E9gSNs/2/dtxWl6e982x9pM74az3zg68BFjP0c/xR4ge0fthVbzyjE2E/SXsBzKP2EZ9s+d+gxJHmsGklrAtvVzRts/67NePrVL70jge3rrmuBY7rwZQfLL7M/S2mrv6rufjKwCPjr3sihrpD0bPo+yw6OvDkC+HtK566B3wAf7MrAAwBJawEHM/Zv8ou1qbITRiHGLknyWAWS/gw4AfgRJfNvARzakaG6bwFOsb207VimIulxrPiPep3tm9qMZzxJ/wWcBJxh+zdtxzOIpE16JwWSHkn5P9368Nx+kj5B+RK+aMont2QUYuyRdA+1v6PP3ZSTr7+1ffMw4kifx6r5CPAc28+0vTvwXOBfW46pZzPgYknflvQaSV3qQwDK8GFJf0/5ovtavXUqcVTHAfsCt0j6kqT96xVnl1wl6VxJh1E6zzuVOKobgY9I+pGkD0naoe2ABhiFGHs+CryV8n99c+AtlD6PU4DPDSuIXHmsAklX237SVPvaUodp7g4cCOxHaRo6GfhKF75cJD2ZEtufU1ZAOxk41XZXOvTHkLQO8EJKzE8FzgJObqOdebw6SXBPSmzPAy6mfJ5n2r6vzdjGq30xB9bb2pQ4T+lSf8KIxPg927uO23eJ7d0kXWX7yUOJI8mjOUmfo1w2fqHuOhhYw/Zh7UU1WN+Xywcpc1Me3nJIY9RRYAcALwGWUL6Uhz5yZLokPYnSZPkk26u3HU+/elW0D+WL71mUDvOD241qMEk7Us6SO/c59nQ1RkkXU1o6ehUOXgq8uSaPK23vMIw40my1al5D6Ux7A/BGykzzTowQ6ifpT4D3AccAD1A6VTvF9iW23wQcQplX8YmWQ1qJpE0kvb7OOP8qZSLjTu1GtTLbD1D+Fq8HfgUsaDeisSQ9TNK+kk4CvgH8kHLS0BmjECPlZPUvgDuAn9b7B9cr5CMnO3A25cpjjqlDDg8EDqKUTjmFcjY/lE60JiTtTInzJZTBB6dQyiz8rM24euoY+oOAxwP/SWm++G67Ua1M0paUq7eDKCOuTqHEen2rgVV1WOlBwPMp82NOAb7apUEIoxBjj6Snjf87HLTvIY8jyWP6JJ1q+89r3ZuVPrgu9HlIupkV7bTXjHtsZ9uXtRPZmDj+ifJl9wtWfNF1bnSYpOMpn+V5tn/ft38LSs2rf24tuBWxXETpOD2N8jkuajmklUj6FuVz/LLtn/ftXxvY1/ZprQW3IpbOx9gj6XLbT5lq30Mtta2aeWP9+YJWo5iE7cf1b0tawIorkbspBdXadj+wz/hOSElPA15u+3XthDVWfx+WpI2Al1E+x80pVyJd8Hbg2+47C5S0LSXOA20/sbXIKtvP6t2vfXDPocT3XEr9rda/mEchRklPpUxanFcnh/asCwy9TybJowHbt9e7r/W4aqUqlXZbr2AKy0eMHFRvyyil4xfa/lGbcfXYfm/vfh0S+XLKyKtb6M6XMrXsx4so8W0HfIVStnvzVgPrY/tCAEmbUq7mXg48CfgA5d+/EyTtTomt1yz0NGAb2/e2GlifEYhxTUq9sjUYW8PuV5RO86FKs9UqmOCysRNDdWszxnqsaA66UdIttrdpObTlJG3HiquhuyjlVN5ie6tWAxtH0n2UL5F3UirqWtLN46/u2tTXL7M5cGq9ndGxf++lwP9SSqZ81fY9Hfyb7HyMPZK2sv3jtuPIaKsG6qS7a4DHS7q673YLcHXb8VV3Us5KNmFF5deunSH8gFJKfF/bT7f9cVasi9Ilf08Z638s8PbaHNQ1x1CaLF5u+522r6Z7/96nU/plDgD2reVpEuOq+6yk9XsbkjaQdPawg8iVRwMqlUo3oDQJHNX30D39nWxtq3G+hHJG+keUctPP7UJRRABJL6Jcefwp8N+Uq6TPdvEsD5aXUTmIEvN84GjKhMvWJ46N64vZhHLl8UrbW7Qa2Dh14uqzKHE+j9JO/1fAWV2pZTYKMQJIusL2jlPte8jjSPJYdSoFCJeXvXatatolNcbeMM4tuvSlUs/u9qfE9mzK5LuvuJYV76I6d+YgSoXiTl2JSNqcFc2BD6d8lp2b2yPpYZTFwA6ilPnZqOWQVtLlGCUtBl7ksVWUvzLs0VZJHqtA0r6U+jKPpUzU2Qq43vb2kx7Ysq60lQ4iaUPKGfQBtp/ddjyjTtLjKaOt3jvlk1skaZ2ulVEZr2sxStqbUnftwrprd+Bw20NtukryWAWSrqKcKZ9ne0dJzwIOsn14y6FFxB+A2ly5G6Wq98VtTKxNh/mq+Z3LMqqrSVrN9reAHVqOKSL+ANS+mb2Bp9j+GvBwlUXghirJY9X8UmXthG8DJ0n6N8p8ipiDJL1AZYnciC74JKW6c28ezz2UUXdDlf8Qq2Y/4D7gTZTRQjdR1n3oDEnbSTpf0vfr9pMkvXOq44ZN0laS9qz311HfetwdciBwo6QPS/rjtoMZRNLpkp7f5SRX/yY/I+kcSd/s3dqOq98oxAjsWqsw/BbA9i8oEwiHKn0ec5SkCykLxny6N4RP0ve7UK6ip05wOxzY0Pa2KkUdP2V7j5ZDW4mkdSlneodRxv8fTyk42fr6KAA1AR9GaQc/Dfi87R+0G9VYta/wU8Bi+ub12F7cWlDjjEiM36MMc7/M9lMkzQPOGfZQ3ZQnaUArL/+oui3AttdtJbDBHm770tI8ulzXmtZeB+wCfA+gzobfuN2QBrP9K0mnA+sAf0MpW/JWSR+rkxxbZfs84Lw6x+cg4FxJt1JWmPsP279rNcBimTu0rvoERiHGj1FK5Wws6R8ppUmG3qqQ5NGA7S42qUzkZ3VGtAEkvRS4ffJDhu5+2w/0EpykNejgrF5JL6Sc1W9LWQBsF9t3SHo4Ze2M1pMHgMqSw6+grO9wBWX99acDhwJ/1l5ky31N0mspX3z393Z2aYItHY+xNkveAryNUqVBwP5uofx+mq1WkaSnUP5jmlL36IqWQxqjzoo+jnJ5+wvKH9wrulIcEUDSh4FfUhaCej3wWuA62+9oM67xJJ1ImQH/7QGP7WH7/BbCGh/HfwJPoCS3z/cV8UTSItutV1OuZXzGc8dqhY1CjBfbfmrrcSR5NCfp3ZQJbb0KsPtTFjF6f2tBTaDO4l6tK23z/eqQw7+mlL8WcDblS7pTf5SSPjSoivL4fW2S9GzbXevYjYeApPdSaun9Z5v/V5I8VoGk64Edbf+2bq8DXG67MyNxNLbef8/dwGLbVw45nJXUy++ru9SBPxF1u4ryiyd73HaXStw/jLKE8+511wWUAR1d6I8BRibGeygrRi6jjLhqpc81fR6r5keUmla/rdtrUYbrdsnCevta3X4+cBlwhKTTbH+4tcgA27+XdJWkLbtYEwxKFWVKU9q2kvqrJj8K6MpytJMNETcdWh+FUp34YZR5ClD6Zo6lXH12Redj7Erfa648GpD0ccp/yC2BnYFz6/ZelH6PA1sMbwyVEs0v6VUDrZMav0wZJbTY9oI24wOo4+d3pqyZsXytaNsvbC2oPhqRKsqjQtJVtp881b42dTlGSU+w/YPa37oS25cPM55ceTTTWx96MWU0Rs8Fww9lSlsCD/Rt/w7YyvZ9ku6f4Jhh63TRPkpTwI8krbQsrqQNu5BAJL3C9n9M0EyJ7Y8OO6ZJPChpW9s3wfJBHV1bx6XLMb6ZMi/qIwMeM6Xe3tAkeTRg+4S2Y2jgi8Alks6o2/sCJ9cO9OvaC2sF1yVUO+yLlPXqF7NiPk+PgS6MwHlE/dmJpowpvBX4lqSbKZ/lVpQh0F3S2Rh7hVfdt956m9JstQrqTOgPAAsYu55HF75MlpO0kLIOsyjNaoumOGSoxk26XJPS1vybjk22jFkkaS3g8ZS/yR/Y7spV8HJdjrHO5Xk5ZVg2lHlGX2zjKjjJYxVI+g5lNbl/pZzRH0b5LI9uNbABNAILVvVI2p8yAa8TCxhN1LbcM+w25slIWpuy6t32jP33/svWgqp6w4gnGhnWhRFhIxLjHwPfpAxpv4KS3Hak9Lk+e9jlaNJstWrWsX2+JNXFld4j6X8oCaUT6qzoj7BiwaotKWuHd3bBKttflXTU1M8cml7b8tqUkWtXUf7DPolSUuXpLcU1yBco/77PBd4HHEw5K+2CZ1K+9AaNDOvKiLBRiPEfgDfaPrV/p6SXAP9IWXp6aHLlsQokfRd4BmX00jeBnwAftP34VgProxFYsGrcWd5qlC/oZ3Zh9mw/SacA/2j7mrr9ROAttl/ZamB9VNew7s0/qfMVznaHVmWUtI3tW6ba16Yuxyjphom+YyZ77KHS2fLNHfc3lDWi3wDsRKkndGibAQ0wCgtW7dt3ey5lXYL9Wo1osCf0EgeA7e/Tvc+yN4ntlzW5rQds3V44A50+YN+Xhx7F5Loc429W8bGHRJqtVoHty+rdX9ORkRgDjF+w6g66V1X3s7bHTLaT9DRKM1uXXC/ps8B/UJowXkF3moR6jpO0AfAu4EzgkfV+6yQ9gdJcut64q8116eufadMoxEipojtoSLaAecMOJs1Wc1Qdknsf5eryYMqZ6H90YW5CzwRlP1ba17baGd1fsuLbwLG98jQxOUn7Ueq/vZCS2HruAU6xfVEbcfUbkRgn7VO1PdR5U0kec1SXi/lJeiql2u/fUEas9awLvKgLs3lHiaTHUyaP9Q/fPM72D9uLamWSnmr74rbjmMwoxNgV6fOYu/YasG+foUcx2JqUZpU1KJPberdfURa26QRJp9af10i6evyt7fhgeSK+gNKEehxl8affABdI2q3F0AY5QtL6vQ1JG0j6XIvxDHKFpNdJ+qSkz/VubQfVRbnyWAWSNqcsAPR04PfAdyhD6Ja2Ghhjivk9jrHFGh8FfNf2K1oJbABJW9Whzp0kaVPbt0vaatDjXYhd0jeAD9m+YNz+ZwJH2e7KCcPyEWFT7WuTpNMoQ55fTt+QZ9tvbDWwDkryWAWSzqWUrvhC3fUK4GDbg872h2qUivmprL38Nlae2NaZ4aX9VNYxXz7IpAufp6Qf2t5ugseGPnxzMnX4+J/Z/kXd3hC40PaftBvZCqMw5LkrMtpq1cyzfXzf9ucl/U1bwYyzOqX5p7PF/PqcBHyJUj/qCMpw5ztbjWgASa+mnIXex4pyKl2pbTXZIl9DH745hY8AF0n6MuXz+3PK5LYuGT/k+f/o2JDn2vR3CCWu/pOZNwwzjiSPVfMzSa8ATq7bBwF3tRhPv14RPxhbyA+684XX82jb/y7pjbVI4oWSulgs8S3A9rZ/1nYgA2wh6WMD9gvYbNjBTMb2iZIWUSavCnix7U4U6ewzaMjzu9sNaSVnAZcA11CazVuR5LFq/hL4BGWkkIGL6r7W2d6m7Rga6J3l3S7p+cBtwOYtxjORm4B72w5iAm+d5LFOFcKsNqQUvzxe0ryuzN7usf3ZevdCunWi1W9t2wNL8A9T+jzmsFrfavlymra/3mY840l6AfA/wBaUAQjrAu+1feakBw6ZpB2B4yn1rJZXWB12M8Goq/MUFgKPt72dpMcCp9l+WsuhjdS6KJLeRBld93XG/j0OtUk6Vx4NSJrs8tW2/2FowUxB0gcpq/SdVHe9UdLTbL+9xbCWk7Q6ML8mtLuBTqxRMIFPU2qYtdpMMAe8iFIF9nIA27dJ6so6JKO0LsoDwD8D76DFPrhceTQg6W8H7H4EpRT2o20/csghTajOQ9jB9u/r9urAFbaf1G5kK0j6VlcWtpmMpIts/2nbcYw6SZfa3qVXRaBWQbi4S3+To0DSTcCubffB5cqjAdvLl3+sZ0xvpNS2OoXBS0O2bX2gdym7XotxTOQiSZ+gjLjqX8O8M+tkVN+SdDjwNVpsJpgDTpX0aWB9Sa+i9BN+puWYAJhg0MFyHWuivJYO9MEleTRUx6a/mTJ56ATgKb1x6x3zAcps2W9RRrbsDnSiyapP72z+fX37hr4W8zS8vP7s//w6MXJN0sdZ0XSxkq586UkS5SThCZSh5I8H3m373FYDW2Fx/fk0ygqhX6rbL+t7rCseBK6s/7db64NLs1UDkv4ZeDGlDMQxtn/dckgrqWfyX7R9kaRNKf0eAr5n+//ajS5mm6TeUgADv/Rsv6mVwAaQtNj2Tm3HMZn6hfwc27+r2w8DzulS82rfv/kYtk8YahxJHtMn6feUTL+MsWd7onSYt772tqQ3AgcCm1K+SE62fWWrQU1A0ibAPwGPtb2PpAXAU23/e8uhjSHpkEH7bZ847FgmMiJfescAn+9b0qBzJN1A+Rv8ed3eALikSzP1uyLJY46q9ZgOrLe1KRMaT+lSpdVal+l44B22nyxpDUqnfmfKVcDypqGetYE9gMttd6mIY+e/9CRdB2wH/JjSx9U76epMh7mkw4D3AN+qu54JvGfYZ/WTkTSf0iy9gLFlfTLaKmZXnafwOeBJtldvO54eSZfZ3rm/OJ6kK23v0HJok6r1w75g+4Vtx9IzIl96nS0w2U/SY4Bd62bnmnslfQc4mjJJeV/KoB3ZnnS9j9mWkuxzlKSHSdpX0knAN4AfAi9pOazxfiPp0dQmwFpC/O52Q5qWe4H5bQfRr9Za2xX4Sr09tSuJoxaUhFKHa9Cta+4Hbgd+AWwnafcpnj9s69g+n5Iwfmz7PbQwyCSjreYYSXtRam09H7iUMoz4cNtdK5IHZdTamcC2kr5LWUqzM01BPZK+xoo+rtUozQWnthfRyupopj2Bx9l+n6QtJe1i+9K2Y6NUoH4BK+qu9ddc68SotR5Jf00Zgr85cCWwG3Ax3RoB+FtJqwE3SjoS+Amw8bCDSLPVHFM7Tr8InD4K8xBqP8fjKV8oN/Q6fLukro3Rswz4sTuwdks/ScdSZr8/2/Yf1z6Pc2zv3HJoI0XSNZQRipfY3kFlbfP32j6g5dCWk7QzZbXI9YF/oMzh+rDtS4YZR6485pguja6Zisra4K+lLKpl4H8kfcodWxu8Vvztul3rrO0rAGz/QtKabQfVU08S9mHFUrnXUdbJWNZeVAP91vZvJSFpLds/UFnmtzP6Rqv9mtLf0Yokj2jTiZQ2795opoMoC2y9rLWI+ki6h8ET8DozNLvP72oJml7/0Tw6UoerFkD8FqUf4QrK5/cC4KOSnmX7tjbjG2dpXS/jq8C5kn5BqfbcGZK2o1RT3oqx63kMtWktzVbRGklX2X7yVPu6QB1bLnU8SQcDBwA7AZ+n9B290/ZpbcYFIOnzwJW2/9+4/W8AdrI9cNJb22pz5XrAN7rUnKqyIuOnKH1ID/b22x7qTPhcecxRtSPtpI6WTum5QtJuvbZaSbsC3205pol0+izL9kmSFlPmoAjY3/b1LYfVs5vtV47faftjdX5KJ9m+UNJzKIsvtb7EdJ9lto9tO4gM1Z27HgNcJulUSXvX0ThdsyulOOKPJP2IMqrlmZKuqVWBo5mNgHttf4Ky2mVXFga7b5LHWi/wByDp2ZJ+KOnXkv5D0gKVVQ8/ALT+RQ2lrl6trfc1Sa+VtGlvX90/3HjSbDV31YTxHEqn2kLK8NJ/t31Tq4FVE00a62l78pikF/dt/gtlOdrlbP/ncCOamLq90NLNjPvseg9RRgltO+SQVg6kDDR4E+UEZh9Kf9y7bP9bq4H1kXQLKw917nFmmMeskvRkSvLYm9JpuRtwru23tRpYVYeUbsHYjr9OlGSXdPwkD9t2J5YehjIzn7rQUt9s/au7UPpjis8R262NGOpRXWOkb/umLiS1LkufxxxVOyMPBX4GfBZ4q+3f9SYXAa0nD0n/ALySskZ4/4ponZiQ1YUvtQYesG1JvdFWj5jqgGEZkc9x/XFXmurf7tJVJoCkJ7JybauhFupM8pi7Hg28eHzTj+3fq6wd3gV/Dmxr+4G2A5kDOrvQ0oi4kFInatC2gc4kj9pE+WeU5HEWpZntO5SmtuHFkWaruadeXVxt+4ltxzIZSacDr7F9R9uxzAW1NM1z6uY5HVpoKWZRnQX/ZEoF6ierLG3wWdv7TnHorMqVxxxUry6ukrSl7f9tO55J9FY7/D5jV0TrTLXaEXMNsA7lTPmalmOJh8599f/4slp08g5aqA+W5DF3bQpcK+lSxq4P3qUv5hOAD1G+6DoxG3oQSQ8H/hbY0varVNZTeLztr7cc2nK1oN+7gW9SRuN8XNL7bH+u3chWGrW2kq71J4yARXUW/GcoEwV/TSmCOlRptpqjxhXzW65LdZokXWh7YJxdIulLlP+kh9h+oqR1gIu7tO5InWz3p7bvqtuPBi7qwmJQfaOtNqasW//Nuv0s4ALbkyaXWKEOv9/c9q11e2tgXdtDnxeVK485qs6O3QqYb/u8evbcmYWgqsWSPkApy97fbNWJobp9trV9gKSDAGzf18FJl0sZuzbGPcCtLcUyRm+0laSvAwts3163NwWOaTO28bp+lVlH1H2VUoYG2z9qK5Ykjzmqjrg5HNgQ2BbYjFIPZ4824xqnVytqt759nRmq2+eBerXRGwa7LX3JriN+AnxP0hmUOPcDLpX0ZgDbH20zuGrrXuKofkpZlrZLjqdcZT61bi8FTgM6kTyqSyTt7JbXgk/ymLteB+wCfA/A9o2Shr5gzGRGqHz8e4D/BrZQWZnxaZT5KV1yU731nFF/PqqFWCZygaSzgZMpCe5AViyb2xWjcJX5LODVklpdCz7JY+663/YDvb97lfUUOtXBVYcY/hPwWNv7SFpAWT7131sObQzb59Sig7tR/qO+0fbPWg5rDNvv7d2vs/Z/6Y51aNo+snaeP6PuOs72V9qMaYBRuMrcp+0AIB3mc5akDwO/BA4BXk9ZdOk62+9oM65+kr5BaSZ4Rx2vvgZl7PqftBzaGJLOpJwtn+mOLecr6d3AqXXRorUo69XvQFnx8OW2z2szvlFT58q8kzIB7xzqVabtC9qMq98ERRDvGXbZ+FTVnbuOAu6kDIN9NXBWVxJHTRIAG9k+lTpMt64q9+CEB7bnI5Sz5esknSbppSqrIHbBAUCvrPmhlP/T84BnUq7qOkPSiyXdKOluSb+SdI+kX7UdV0+dXLsB8GJKs+TJwMIuJY7qcsr/7R9SSg3dCdwi6XJJOw0riDRbzV2vrxVBl5eokPTGjlQJvRR4CvCbOqS010SwG3B3m4ENUoc3X6iyUt+zgVcBnwO6sJLgA33NU88FTrb9IHB9X5Luig8D+3ZonZEx6sS7I+sJzX+1Hc8k/hv4iu2zAVTWHNmbUjX7k5SlDh5yufKYuwatzvbKYQcxgV4H5Jspw3S3lfRdSm2e17cW1SRqO/hLgCOAnSkTHLvgfklPVFl29lmUppaeh7cU00R+2tXE0edcSW+RtIVaXCtjCgt7iQNKnxywe11Uba1hBdG1M5OYoTpK5OXANrWtvudRwF3tRLWSeb0hpMBXKMXdROmY3BPo1EJQdZLgrpQzvmMoE9u6MiP+jcCXKU1V/2r7FgBJz6OsF94li+pn+VXGzuvp0gzzXpn91/XtMy2U/5jEzyX9HXBK3T4A+EW9Mh7a32U6zOeYOjFwG0rdqKP6HrqHUixxWSuB9ZF0O2V1toFDIPtHDnWBpL0pa6B0sT9mZGjwuh6dWhdlFEjaCDgaeDrl/9B3gPdSmny3tL1kKHEkecxNkj5k+++m2tcGjVt4p6skPdv2NyeqzdSxM+aYJV1YK2MUpNlq7toLGJ8o9hmwrw1dm3Q1kWdS6jANKnXdqTUeukzS22x/WNLHGTDXyPYbWghroK6slTEZSdtRlvXdmrErcA61MkOSxxwj6TWUOR3bSurvO3gU8N12olpJl0qkTMj20fXu+3p9CT2StmkhpFHV6yRf1GoU0/NSVqyVcVhvrYyWYxrvNEqpoc/S4tD2JI+554uUiWIr9XnY/nk7IY3VlTgaOJ0ytLjfl6nF6do0IuXOt5W0M3BSF/rcptCJtTKmsMz2sW0HkeQxx9i+m9JxdhBArWe1NvBISY/s+OJQnSLpCcD2wHrjvqTXpa89vGW9JrWB5c7pRtPa5sC/AU+oV8MXUa6CL+7giUQn1sqYwtckvZYyUrF/1NpQP8t0mM9RkvYFPgo8lnL2tBVwve3tWw1shEjaD9gfeCFlPkrPPcApti9qI65BarnzV40vd96ltTIkrQkspCS5p9bbL20vaDWwCbS5VsZkJN0yYLdtD/UKKVcec9f7KYX8zrO9o6RnUa9GYnpsnwGcIempti9uO54pjEK583UoV23r1dttdGS5XEkTjv6T9JQurTFjuxP9bUkec9fvbN8laTVJq9n+lqQPtR3UiLpC0usoTVj9wze7ND+hs+XOJR1H+ezuoSwRcBHwUdu/aDWwsT4yyWOdWGOma/1bSR5z1y8lPRL4NnCSpDsolVajuS8AP6DUjnofcDArRhB1QsfLnW9JKZtxI2XRqqWUis+dMSJrywwaMt4z9KHj6fOYoyQ9AriPUr/sYEozwUm9Na5j+iRdUZv+rrb9JEkPA84e9rj6UVYXVNqe0t/xp8ATgZ9TOs2PnuzYYar/tq8Bdq+7LgA+Pexy56MghRHnKNu/sf37OjTyv4CPJ3Gsst4Xxy/r7OP1KBO0OqPr5c5dfJ8y8e4blNFW21Jqc3XJsZQh2J+st53qvk6QtHotT9LbXlPS4ZKGfiWcZqs5ppY1/yDlrO4fKE0uGwGrSTrE9n+3Gd+IOk5ldb53UUZdPRJ4d7shraSz5c4lvYFytfE0SiL+LnAxpax9JzrM++xs+8l929+UdFVr0fSRdCDwacpSBjdSlkf+AnAZpXVhqJI85p5PAH9POTv+JrCP7UvqnIWTKZVhowHbvRnGF9K9CWM9XS53vjVlUuWbxo0I66IHJW1r+yYASY+jOwuUvRPYyfaSOjrsYuDAtvq20ucxx0i60vYO9f71tv+477ErbO/YWnAjpq9s/EC2PzqsWKYi6d+Ax9DtcuedJ2kPytLIN1NqsG0FHGa79ZFr4wuKSvqB7Se0FU+uPOae/nr+9417LGcKzTyq7QAaWBe4F3hO374Ub2zI9vmS5gOPpySPH9i+f4rDhmXjcSc0j+zfHvbJTK485hhJDwK/ofzhr0P5QqFur237YW3FFtFVtfbWrbb/r24fQlk58sfAe7pQRqVW/J3QsNfBSfKImEItgX0ssIntJ0p6EvBC2+9vObSRKnfeZZIuB/a0/XNJu1NW6Xs9sAPwx7Zf2mZ8XZRmq4ipfQZ4K2WkC7avlvRFSgmYto1SufMuW73v6uIAyiTL04HTJV3ZXljdleQRMbWH2760zHNbriuz9Uep3HmXrS5pjfoZ7gEc3vdYvicHyIcSMbWfSdqW2iwk6aVAV4acjlK58y47GbhQ0s8oA03+B0DSH1GWOIhx0ucRMYU61v84ykS3XwC3AAfb/nGrgfUZtXLnXVQn2G4KnGP7N3XfdsAju1RVV9IbKcOJ76GsJrgjcJTtc4YZR648IqZg+2Zgz1ovbDXKmekBlJE4XdHZcuejwvYlA/b9sI1YpvCXtv9N0nOBecBhlGSS5BHRBXUZ0tcBmwFnAOfV7bcAVwEntRddMSLlzmN29Trfngccb/sqjeuQG4Ykj4iJfYHSTHUx8CrgbcCawP62r2wxrn6dL3ces26xpHOAbYC3S3oUYycHD0X6PCImIOka239S768O/AzY0vY97UY21qiUO4/ZIWk1yvyTm23/UtKjgc2GvVxurjwiJrZ8DQfbD0q6pWuJA0q5c+D7kn5JGRl0N/ACYBcgyWOOkPQE2z+gJA6Ax7XQWrUinlx5RAzWV+oFxpZ7EeU7e922YuuZpNz5d4FrbA+9OSMeGpKOs324pEFFGj3sxcmSPCJGmKSPUud2jEC585gFkta2/dup9j3kcSR5RESMjvGl2Sfa91BLn0dExAiQ9BjKsPF1JO3IiiG76wIPH3Y8SR4REaPhucArKSVpPsKK5PEryuqhQ5Vmq4iIEVGH6R5ku/UJqqu1HUBERExPHT336rbjgFx5RESMFEnvotRX+xIrhpIz7CrKSR4RESNE0i0Ddtv244YaR5JHREQ0ldFWEREjRNIhg/bbPnGYcSR5RESMlp377q9NWTb3cmCoySPNVhERI0zSesAXbL9wmL83Q3UjIkbbvcD8Yf/SNFtFRIwQSV8Dek1GqwELgFOHHkearSIiRoekZ/ZtLgN+bHvpsOPIlUdExAiQ9EfAJrYvHLf/GZLWsn3TMONJn0dExGj4f8CglSzvq48NVZJHRMRo2HrQOuW2FwFbDzuYJI+IiNGw9iSPrTO0KKokj4iI0XCZpFeN3ynpr4DFww4mo60iIkaApE2ArwAPsCJZLATWBF5k+/+GGk+SR0TE6JD0LOCJdfNa299sJY4kj4iIaCp9HhER0ViSR0RENJbkERERjSV5REREY/8fAs/O8Lmz8bEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.bar(accuracy_drop_log.keys(), accuracy_drop_log.values(), color=\"maroon\", width = 0.4)\n",
    "plt.xticks(rotation=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7e5e569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features are ranked from best to worst (based on how removing them impacts the accuracy of grad_boost)\n",
      "**************************************\n",
      "Feature 1.Curtis RIngraham Directge, drop in acc 0.007619539043687618\n",
      "Feature 2.Relative Humidity AVG, drop in acc 0.0005951152390780701\n",
      "Feature 3.Wind Speed Daily AVG, drop in acc -0.0011695906432749315\n",
      "Feature 4.Battery Voltage AVG, drop in acc -0.0011764705882353343\n",
      "Feature 5.Wind Direction AVG, drop in acc -0.005872033023735845\n",
      "Feature 6.Solare Radiation AVG, drop in acc -0.005875472996216047\n",
      "Feature 7.Temperature AVG, drop in acc -0.009969040247677974\n"
     ]
    }
   ],
   "source": [
    "def criteria(l):\n",
    "    return l[1]\n",
    "\n",
    "sorted_accs =  sorted(accuracy_drop_log.items(),key=criteria, reverse=True)\n",
    "\n",
    "print (f\"Features are ranked from best to worst (based on how removing them impacts the accuracy of {best_model_name})\")\n",
    "print (f\"**************************************\")\n",
    "\n",
    "i=1\n",
    "for entry in sorted_accs:\n",
    "    feature_name = entry[0]\n",
    "    acc_drop = entry[1]\n",
    "    \n",
    "    # We do not want to print \"No ablation\"\n",
    "    if feature_name != \"No ablation\":\n",
    "        print (f\"Feature {i}.{feature_name}, drop in acc {acc_drop}\")\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a32e04",
   "metadata": {},
   "source": [
    "From here, we can see that the most important feature is \"Curtis RIngraham Directge\" which stands for all the one-hot encoding features. It seems luike Route and Relative Humidity are the most important features in terms of model performance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552cd2b6",
   "metadata": {},
   "source": [
    "### 2. MinMax Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c15d0db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation accuracy for model lr = 0.6293257653938769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation accuracy for model svm = 0.6087994496044031\n",
      "Mean cross validation accuracy for model decision_tree = 0.6076332989336085\n",
      "Mean cross validation accuracy for model random_forest = 0.634031647746818\n",
      "Mean cross validation accuracy for model grad_boost = 0.63406260749914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation accuracy for model voting = 0.6322738218094257\n",
      "Best model is grad_boost with 10-fold accuracy of 0.63406260749914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "features = mtrainier_features_minmax_df.to_numpy()\n",
    "labels = mtrainier_labels_df.to_numpy()\n",
    "\n",
    "_x, x_test, _y, y_test = train_test_split(features, labels, test_size=0.10, random_state=42)\n",
    "\n",
    "k = 10\n",
    "\n",
    "# We can use sklearn's cross validation score directly\n",
    "# We can speed up training using n_jobs parameter which specifies how many cpu_cores to use\n",
    "\n",
    "best_model_name = \"\"\n",
    "best_model_valid_accuracy = 0\n",
    "best_model = \"None\"\n",
    "\n",
    "for model_name in all_models.keys():\n",
    "    model = all_models[model_name]\n",
    "    cv_scores = cross_val_score(model,_x,_y.flatten(), cv=k, n_jobs=4)\n",
    "    average_cv_score = cv_scores.mean()\n",
    "    print (f\"Mean cross validation accuracy for model {model_name} = {average_cv_score}\")\n",
    "\n",
    "    if average_cv_score > best_model_valid_accuracy :\n",
    "        best_model_name = model_name\n",
    "        best_model_valid_accuracy  = average_cv_score\n",
    "        best_model = model\n",
    "\n",
    "print (f\"Best model is {best_model_name} with {k}-fold accuracy of {best_model_valid_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6337d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for model 0.6263157894736842\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(_x,_y.flatten())\n",
    "\n",
    "y_pred_test = best_model.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_pred_test, y_test.flatten())\n",
    "\n",
    "print (f\"Test accuracy for model {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9675f085",
   "metadata": {},
   "source": [
    "Best model is <mark> grad_boost with 10-fold accuracy of **0.63406260749914** with a test accuracy of **0.6263157894736842** </mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db3881d",
   "metadata": {},
   "source": [
    "###  For MinMax Scaling, we will run feature abalation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6adc2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature Battery Voltage AVG\n",
      "Mean cross validation accuracy = 0.6346508427932577\n",
      "Removing feature Temperature AVG\n",
      "Mean cross validation accuracy = 0.6440282077743378\n",
      "Removing feature Relative Humidity AVG\n",
      "Mean cross validation accuracy = 0.6340522875816994\n",
      "Removing feature Wind Speed Daily AVG\n",
      "Mean cross validation accuracy = 0.63640522875817\n",
      "Removing feature Wind Direction AVG\n",
      "Mean cross validation accuracy = 0.6405159958720331\n",
      "Removing feature Solare Radiation AVG\n",
      "Mean cross validation accuracy = 0.6399346405228759\n",
      "Removing feature Curtis RIngraham Directge\n",
      "Mean cross validation accuracy = 0.6258513931888545\n"
     ]
    }
   ],
   "source": [
    "# Let's run ablation tests on our best model\n",
    "# You could choose any model to do this test\n",
    "best_model = GradientBoostingClassifier()\n",
    "\n",
    "feature_names = mtrainier_features_minmax_df.columns \n",
    "\n",
    "# Let's maintain an accuracy dictionary\n",
    "\n",
    "accuracy_drop_log = {\"No ablation\":0}\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    # we are going to drop one feature at a time - which includes the entire one-hot encoding key when we do route\n",
    "    feature_name = feature_names[i]\n",
    "    print (f\"Removing feature {feature_name}\")\n",
    "    \n",
    "    #first categorical feature derived from one-hot encoding\n",
    "    if feature_name != 'Curtis RIngraham Directge': \n",
    "        x_ablated = np.delete(_x,i,axis=1) \n",
    "        cv_scores = cross_val_score(best_model,x_ablated,_y.flatten(), cv=k, n_jobs=4)\n",
    "        average_cv_score = cv_scores.mean()\n",
    "        print (f\"Mean cross validation accuracy = {average_cv_score}\")\n",
    "        accuracy_drop_log[feature_name] = best_model_valid_accuracy-average_cv_score\n",
    "    else: #to represent all the routes \n",
    "        x_ablated = np.delete(_x,np.s_[6:28],axis=1)\n",
    "        cv_scores = cross_val_score(best_model,x_ablated,_y.flatten(), cv=k, n_jobs=4)\n",
    "        average_cv_score = cv_scores.mean()\n",
    "        print (f\"Mean cross validation accuracy = {average_cv_score}\")\n",
    "        accuracy_drop_log[feature_name] = best_model_valid_accuracy-average_cv_score\n",
    "        break \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2df48a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 8 artists>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7],\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.bar(accuracy_drop_log.keys(), accuracy_drop_log.values(), color=\"maroon\", width = 0.4)\n",
    "plt.xticks(rotation=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5d8badc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features are ranked from best to worst (based on how removing them impacts the accuracy of grad_boost)\n",
      "**************************************\n",
      "Feature 1.Curtis RIngraham Directge, drop in acc 0.008211214310285486\n",
      "Feature 2.Relative Humidity AVG, drop in acc 1.0319917440604343e-05\n",
      "Feature 3.Battery Voltage AVG, drop in acc -0.0005882352941176672\n",
      "Feature 4.Wind Speed Daily AVG, drop in acc -0.0023426212590299533\n",
      "Feature 5.Solare Radiation AVG, drop in acc -0.005872033023735845\n",
      "Feature 6.Wind Direction AVG, drop in acc -0.00645338837289311\n",
      "Feature 7.Temperature AVG, drop in acc -0.009965600275197772\n"
     ]
    }
   ],
   "source": [
    "def criteria(l):\n",
    "    return l[1]\n",
    "\n",
    "sorted_accs =  sorted(accuracy_drop_log.items(),key=criteria, reverse=True)\n",
    "\n",
    "print (f\"Features are ranked from best to worst (based on how removing them impacts the accuracy of {best_model_name})\")\n",
    "print (f\"**************************************\")\n",
    "\n",
    "i=1\n",
    "for entry in sorted_accs:\n",
    "    feature_name = entry[0]\n",
    "    acc_drop = entry[1]\n",
    "    \n",
    "    # We do not want to print \"No ablation\"\n",
    "    if feature_name != \"No ablation\":\n",
    "        print (f\"Feature {i}.{feature_name}, drop in acc {acc_drop}\")\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7bec3d",
   "metadata": {},
   "source": [
    "We can see that the most important features are still the same with \"Curtis RIngraham Directge\" being on top. It is slightly more important in terms of accuracy compared to Standard Scaling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af637fa",
   "metadata": {},
   "source": [
    "### 3. Removing \"glacier only - no summit attempt\" and \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5a9b286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation accuracy for model lr = 0.6299071207430339\n",
      "Mean cross validation accuracy for model svm = 0.6187616099071207\n",
      "Mean cross validation accuracy for model decision_tree = 0.6105675954592363\n",
      "Mean cross validation accuracy for model random_forest = 0.6275851393188854\n",
      "Mean cross validation accuracy for model grad_boost = 0.6240798073615411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation accuracy for model voting = 0.6334330925352598\n",
      "Best model is voting with 10-fold accuracy of 0.6334330925352598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "features = mtrainier_removed_df.to_numpy()\n",
    "labels = mtrainier_labels_df.to_numpy()\n",
    "\n",
    "_x, x_test, _y, y_test = train_test_split(features, labels, test_size=0.10, random_state=42)\n",
    "\n",
    "k = 10\n",
    "\n",
    "# We can use sklearn's cross validation score directly\n",
    "# We can speed up training using n_jobs parameter which specifies how many cpu_cores to use\n",
    "\n",
    "best_model_name = \"\"\n",
    "best_model_valid_accuracy = 0\n",
    "best_model = \"None\"\n",
    "\n",
    "for model_name in all_models.keys():\n",
    "    model = all_models[model_name]\n",
    "    cv_scores = cross_val_score(model,_x,_y.flatten(), cv=k, n_jobs=4)\n",
    "    average_cv_score = cv_scores.mean()\n",
    "    print (f\"Mean cross validation accuracy for model {model_name} = {average_cv_score}\")\n",
    "\n",
    "    if average_cv_score > best_model_valid_accuracy :\n",
    "        best_model_name = model_name\n",
    "        best_model_valid_accuracy  = average_cv_score\n",
    "        best_model = model\n",
    "\n",
    "print (f\"Best model is {best_model_name} with {k}-fold accuracy of {best_model_valid_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc7b71bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;1&#x27;, LogisticRegression(penalty=&#x27;none&#x27;)),\n",
       "                             (&#x27;2&#x27;, SVC(kernel=&#x27;linear&#x27;)),\n",
       "                             (&#x27;3&#x27;, DecisionTreeClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;1&#x27;, LogisticRegression(penalty=&#x27;none&#x27;)),\n",
       "                             (&#x27;2&#x27;, SVC(kernel=&#x27;linear&#x27;)),\n",
       "                             (&#x27;3&#x27;, DecisionTreeClassifier())])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(penalty=&#x27;none&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>3</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('1', LogisticRegression(penalty='none')),\n",
       "                             ('2', SVC(kernel='linear')),\n",
       "                             ('3', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for model 0.6210526315789474\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(_x,_y.flatten())\n",
    "\n",
    "y_pred_test = best_model.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_pred_test, y_test.flatten())\n",
    "\n",
    "print (f\"Test accuracy for model {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5017b04e",
   "metadata": {},
   "source": [
    "There is some difference when we remove the two columns \"Unknown\" and \"\"glacier only - no summit attempt\". The best model is <mark> voting with 10-fold accuracy of **0.6334330925352598** and a test accuracy of **0.6210526315789474** </mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17743d02",
   "metadata": {},
   "source": [
    "### For the removed parts of the dataframe, we will run feature ablation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6854304c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature Battery Voltage AVG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation accuracy = 0.6199312005503956\n",
      "Removing feature Temperature AVG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation accuracy = 0.6269797041623667\n",
      "Removing feature Relative Humidity AVG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation accuracy = 0.6340144478844169\n",
      "Removing feature Wind Speed Daily AVG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation accuracy = 0.6351909184726521\n",
      "Removing feature Wind Direction AVG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation accuracy = 0.6322669418644651\n",
      "Removing feature Solare Radiation AVG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/wolfpack/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation accuracy = 0.6058789129686962\n",
      "Removing feature Curtis RIngraham Directge\n",
      "Mean cross validation accuracy = 0.6240488476092191\n"
     ]
    }
   ],
   "source": [
    "# Let's run ablation tests on our best model\n",
    "# You could choose any model to do this test\n",
    "best_model = VotingClassifier(estimators=[(\"1\",lr_vanilla),(\"2\",svm_linear),(\"3\",dt)])\n",
    "\n",
    "feature_names = mtrainier_removed_df.columns \n",
    "\n",
    "# Let's maintain an accuracy dictionary\n",
    "\n",
    "accuracy_drop_log = {\"No ablation\":0}\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    # we are going to drop one feature at a time - which includes the entire one-hot encoding key when we do route\n",
    "    feature_name = feature_names[i]\n",
    "    print (f\"Removing feature {feature_name}\")\n",
    "    \n",
    "    #first categorical feature derived from one-hot encoding\n",
    "    if feature_name != 'Curtis RIngraham Directge': \n",
    "        x_ablated = np.delete(_x,i,axis=1) \n",
    "        cv_scores = cross_val_score(best_model,x_ablated,_y.flatten(), cv=k, n_jobs=4)\n",
    "        average_cv_score = cv_scores.mean()\n",
    "        print (f\"Mean cross validation accuracy = {average_cv_score}\")\n",
    "        accuracy_drop_log[feature_name] = best_model_valid_accuracy-average_cv_score\n",
    "    else: #to represent all the routes \n",
    "        x_ablated = np.delete(_x,np.s_[6:26],axis=1)\n",
    "        cv_scores = cross_val_score(best_model,x_ablated,_y.flatten(), cv=k, n_jobs=4)\n",
    "        average_cv_score = cv_scores.mean()\n",
    "        print (f\"Mean cross validation accuracy = {average_cv_score}\")\n",
    "        accuracy_drop_log[feature_name] = best_model_valid_accuracy-average_cv_score\n",
    "        break \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6503b96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 8 artists>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7],\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.bar(accuracy_drop_log.keys(), accuracy_drop_log.values(), color=\"maroon\", width = 0.4)\n",
    "plt.xticks(rotation=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2bbf5e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features are ranked from best to worst (based on how removing them impacts the accuracy of voting)\n",
      "**************************************\n",
      "Feature 1.Solare Radiation AVG, drop in acc 0.027554179566563586\n",
      "Feature 2.Battery Voltage AVG, drop in acc 0.013501891984864178\n",
      "Feature 3.Curtis RIngraham Directge, drop in acc 0.00938424492604073\n",
      "Feature 4.Temperature AVG, drop in acc 0.00645338837289311\n",
      "Feature 5.Wind Direction AVG, drop in acc 0.00116615067079473\n",
      "Feature 6.Relative Humidity AVG, drop in acc -0.0005813553491570422\n",
      "Feature 7.Wind Speed Daily AVG, drop in acc -0.0017578259373922656\n"
     ]
    }
   ],
   "source": [
    "def criteria(l):\n",
    "    return l[1]\n",
    "\n",
    "sorted_accs =  sorted(accuracy_drop_log.items(),key=criteria, reverse=True)\n",
    "\n",
    "print (f\"Features are ranked from best to worst (based on how removing them impacts the accuracy of {best_model_name})\")\n",
    "print (f\"**************************************\")\n",
    "\n",
    "i=1\n",
    "for entry in sorted_accs:\n",
    "    feature_name = entry[0]\n",
    "    acc_drop = entry[1]\n",
    "    \n",
    "    # We do not want to print \"No ablation\"\n",
    "    if feature_name != \"No ablation\":\n",
    "        print (f\"Feature {i}.{feature_name}, drop in acc {acc_drop}\")\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a79a81",
   "metadata": {},
   "source": [
    "We can see that there is a huge shift in terms of importance features from \"Curtis RIngraham Directge\" to now Solare Radiation AVG and Battery Voltage AVG having more importance. In fact, most of the drops in features have some substantial affect on accuracy unlike when we kept all of the features from one-hot encoding.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4f8449",
   "metadata": {},
   "source": [
    "### 4. Taking away the 'Route' feature entirely before feature ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e7c6525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation accuracy for model lr = 0.6134571723426212\n",
      "Mean cross validation accuracy for model svm = 0.618173374613003\n",
      "Mean cross validation accuracy for model decision_tree = 0.6117853457172342\n",
      "Mean cross validation accuracy for model random_forest = 0.6223460612315102\n",
      "Mean cross validation accuracy for model grad_boost = 0.6264396284829722\n",
      "Mean cross validation accuracy for model voting = 0.6240488476092191\n",
      "Best model is grad_boost with 10-fold accuracy of 0.6264396284829722\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "features = mtrainier_no_route_df.to_numpy()\n",
    "labels = mtrainier_labels_df.to_numpy()\n",
    "\n",
    "_x, x_test, _y, y_test = train_test_split(features, labels, test_size=0.10, random_state=42)\n",
    "\n",
    "k = 10\n",
    "\n",
    "# We can use sklearn's cross validation score directly\n",
    "# We can speed up training using n_jobs parameter which specifies how many cpu_cores to use\n",
    "\n",
    "best_model_name = \"\"\n",
    "best_model_valid_accuracy = 0\n",
    "best_model = \"None\"\n",
    "\n",
    "for model_name in all_models.keys():\n",
    "    model = all_models[model_name]\n",
    "    cv_scores = cross_val_score(model,_x,_y.flatten(), cv=k, n_jobs=4)\n",
    "    average_cv_score = cv_scores.mean()\n",
    "    print (f\"Mean cross validation accuracy for model {model_name} = {average_cv_score}\")\n",
    "\n",
    "    if average_cv_score > best_model_valid_accuracy :\n",
    "        best_model_name = model_name\n",
    "        best_model_valid_accuracy  = average_cv_score\n",
    "        best_model = model\n",
    "\n",
    "print (f\"Best model is {best_model_name} with {k}-fold accuracy of {best_model_valid_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e4dcded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for model 0.631578947368421\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(_x,_y.flatten())\n",
    "\n",
    "y_pred_test = best_model.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_pred_test, y_test.flatten())\n",
    "\n",
    "print (f\"Test accuracy for model {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd259927",
   "metadata": {},
   "source": [
    "The best model is <mark>grad_boost with 10-fold accuracy of **0.6264396284829722** and a test accuracy of **0.631578947368421**</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ad0ac2",
   "metadata": {},
   "source": [
    "### For removing 'Route', we will run feature ablation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53d734b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature Battery Voltage AVG\n",
      "Mean cross validation accuracy = 0.6211558307533539\n",
      "Removing feature Temperature AVG\n",
      "Mean cross validation accuracy = 0.6258479532163743\n",
      "Removing feature Relative Humidity AVG\n",
      "Mean cross validation accuracy = 0.6240763673890609\n",
      "Removing feature Wind Speed Daily AVG\n",
      "Mean cross validation accuracy = 0.6328895768833849\n",
      "Removing feature Wind Direction AVG\n",
      "Mean cross validation accuracy = 0.6258513931888545\n",
      "Removing feature Solare Radiation AVG\n",
      "Mean cross validation accuracy = 0.6223323013415893\n"
     ]
    }
   ],
   "source": [
    "# Let's run ablation tests on our best model\n",
    "# You could choose any model to do this test\n",
    "best_model = GradientBoostingClassifier()\n",
    "\n",
    "feature_names = mtrainier_no_route_df.columns \n",
    "\n",
    "# Let's maintain an accuracy dictionary\n",
    "\n",
    "accuracy_drop_log = {\"No ablation\":0}\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    # we are going to drop one feature at a time - which includes the entire one-hot encoding key when we do route\n",
    "    feature_name = feature_names[i]\n",
    "    print (f\"Removing feature {feature_name}\")\n",
    "    \n",
    "    #first categorical feature derived from one-hot encoding\n",
    "    if feature_name != 'Curtis RIngraham Directge': \n",
    "        x_ablated = np.delete(_x,i,axis=1) \n",
    "        cv_scores = cross_val_score(best_model,x_ablated,_y.flatten(), cv=k, n_jobs=4)\n",
    "        average_cv_score = cv_scores.mean()\n",
    "        print (f\"Mean cross validation accuracy = {average_cv_score}\")\n",
    "        accuracy_drop_log[feature_name] = best_model_valid_accuracy-average_cv_score\n",
    "    else: #to represent all the routes \n",
    "        x_ablated = np.delete(_x,np.s_[6:26],axis=1)\n",
    "        cv_scores = cross_val_score(best_model,x_ablated,_y.flatten(), cv=k, n_jobs=4)\n",
    "        average_cv_score = cv_scores.mean()\n",
    "        print (f\"Mean cross validation accuracy = {average_cv_score}\")\n",
    "        accuracy_drop_log[feature_name] = best_model_valid_accuracy-average_cv_score\n",
    "        break \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5304d1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 7 artists>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6],\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.bar(accuracy_drop_log.keys(), accuracy_drop_log.values(), color=\"maroon\", width = 0.4)\n",
    "plt.xticks(rotation=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf9569ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features are ranked from best to worst (based on how removing them impacts the accuracy of grad_boost)\n",
      "**************************************\n",
      "Feature 1.Battery Voltage AVG, drop in acc 0.005283797729618289\n",
      "Feature 2.Solare Radiation AVG, drop in acc 0.004107327141382844\n",
      "Feature 3.Relative Humidity AVG, drop in acc 0.002363261093911273\n",
      "Feature 4.Temperature AVG, drop in acc 0.0005916752665978686\n",
      "Feature 5.Wind Direction AVG, drop in acc 0.0005882352941176672\n",
      "Feature 6.Wind Speed Daily AVG, drop in acc -0.006449948400412686\n"
     ]
    }
   ],
   "source": [
    "def criteria(l):\n",
    "    return l[1]\n",
    "\n",
    "sorted_accs =  sorted(accuracy_drop_log.items(),key=criteria, reverse=True)\n",
    "\n",
    "print (f\"Features are ranked from best to worst (based on how removing them impacts the accuracy of {best_model_name})\")\n",
    "print (f\"**************************************\")\n",
    "\n",
    "i=1\n",
    "for entry in sorted_accs:\n",
    "    feature_name = entry[0]\n",
    "    acc_drop = entry[1]\n",
    "    \n",
    "    # We do not want to print \"No ablation\"\n",
    "    if feature_name != \"No ablation\":\n",
    "        print (f\"Feature {i}.{feature_name}, drop in acc {acc_drop}\")\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046e46a",
   "metadata": {},
   "source": [
    "We can see that removing 'Route' feature matches up with removing the two features \"Unknown\" and \"glacier only - no summit attempt\". The most importance features are now Battery Voltage AVG and Solare Radiation AVG. However, the drops in these features wouldn't really affect accuracy as well compared to removing those two features only. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa63a6",
   "metadata": {},
   "source": [
    "## Insights and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8b3740",
   "metadata": {},
   "source": [
    "I tried 4 different modifications and ran feature ablation on each model. The four modifications were: Standard Scaling, MinMax Scaling, removing the two features 'Unknowns' and 'glacier - no attempt at summit', and removing route entirely from the dataframe. Overall despite doing all these modifications, most of the models were stagnant in terms of model accuracy with it ranging between 0.62-0.63 for test and validation accuracy. However, the changes in terms of feature importance were interesting since \"Route\" was the most important feature for MinMax and Standard Scaling. After I removed those two categorical features and kept the other 20 routes, the importance feature of \"Route\" dropped to third. Battery Voltage AVG and Solare Radiation AVG were both the top features for the last models. I believe that model acccuracy can improve if better data or more features were added.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34ac50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
